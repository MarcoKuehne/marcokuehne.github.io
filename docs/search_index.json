[["index.html", "Becoming Fluent in Data A Personal Journey – Every Time. Preface", " Becoming Fluent in Data A Personal Journey – Every Time. Marco Kühne 2023-04-14 Preface "],["about-the-author.html", "About the author Dust and Dark Teach – Learn – Repeat", " About the author   Welcome! My name is Marco Kühne. The very first thing I want to do is to invite you to call me Marco. That is, if we meet on the street, you come talk to me during office hours, you ask some question; Marco’s the name that I respond to. Web: http://marco-kuehne.com/ Twitter: https://twitter.com/marco_kuhne GitHub: https://github.com/MarcoKuehne I am a PhD candidate in Economics at the European University Viadrina. I am generally keen on teaching topics related to research design, quantitative methods, and statistical software. My main methodological interests in quantitative social science include panel data modelling, causal inference with observational data and R programming. I am also a gardening fanatic, a coffee enthusiast, a committed ballroom and Discofox dancer, a (vegetarian) food lover. I enjoy cutting down big trees and practicing new languages in its own sake. Feel free to contact me! Dust and Dark A dusty lecture hall. The light cuts through the darkness from the left side of the room. A dozen of seats in each bench, only few occupied by small groups of students who were trying to make sure that they sit far from each other and as far as possible from the lecturer. The bearish but competent assistant professor explained how to analyze and evaluate the results of various memory and cognition experiments through boxplots, t-test and the like in that software. My creaky, slow but loyal laptop in front of me. That's where R was introduced in my psychology undergraduate studies. – The Times They Are A-Changin'. This eBook is done in R. Are you eady to join the journey? Lecture Hall. Melanchthonianum. MLU University of Halle-Wittenberg The following animation is created with the gganimate package. It shows past course data. Which graphical feature is used to display 3 data dimensions in a two-dimensional graph: ColorSizeShapeOpacity? How many students participated in summer 2021? Answer: . Teach – Learn – Repeat Teaching and learning are strongly connected. I fell in love with learning by teaching the moment I came across this concept. It put the experiences I made into scientific context. Studying for the undergraduate math classes, I soon became head of the study group, than a private tutor, than a student assistant and a doctoral student, now, teaching stuff for over a decade. Still, I feel that (trying) to teach stuff is the best way of learning it myself. By writing the gitbook I hope to force myself to pinpoint exactly what I know and don't know about data and how to fill the gaps. Luckily, I am not alone with the approach of creating classes or writing books to learn: I could feel that econometrics was indispensable, and yet I was missing something. But what? It was a theory of causality […]. So, desperate, I did what I always do when I want to learn something new — I developed a course on causality to force myself to learn all the things I didn’t know. Cunningham (2021) This project helped me to learn more about R, RStudio, R Markdown, R Bookdown, HTML/CSS, Git and Github, empirical research, causal inference, statistics, math, frustration tolerance and fun. Teaching in 2014. Learning by teaching was originally defined by Jimmy WalesLinus TorvaldsJean-Pol MartinRichard E. Pattis in the 1980s. Did you know that some people who have Wikipedia articles also have user accounts on Wikipedia? "],["about-the-book.html", "About the book Aims of this book Structure Color Components", " About the book I welcome you to join us on our way to become fluent in data. Aims of this book You go from zero you hero in data analysis and data science and will become data fluent and learn major skills that you can use in your academic and business career. The ability to take data — to be able to understand it, to process it, to extract value from it, to visualize it, to communicate it — that’s going to be a hugely important skill in the next decades... Hal Varian, 2009. Googles chief economist. In: McKinsey Quarterly 2009 In addition and independent of a specific career, I would like to foster people's data literacy. Definition Data literacy is the ability to read, understand, create, and communicate data as information. I would like to enable and empower all people to understand the data work of others. Don't take numbers for granted. It's a long journey to get them. Don't be satisfied with a summary or conclusion from someone else. It's worthwhile checking data sources and data work. Either to replicate and validate the data work of others or to form your own opinion. Not to mention, coding is fun. You might be under the impression, to code, your favorite thing must be computers. Or I've heard I'm bad a math, I can't code. None of this is true. Think about it, what is your passion. Learn to code, is something that you can do. And something that may just expand the way you approach and think about the passions in your life. Be their personal or professional.   A wordcloud of 25 students answers (2020) on the question: What do you expect to learn in this seminar? The animation is created by the gifski package. Structure Every chapter covers the content of a week. The first half of the course (chapter 1 -- 7) introduces all the basics from scratch. We measure and collect data to make informed decisions. Most decisions are complex, costly and have long-term implications. It is therefore vital that such decisions are based on the best available evidence. The second half of the course (chapter 8 -- 13) focuses on the analysis of relationships. It opens the realm of research questions and projects. We try to answer apparently simple but intriguing questions from daily life. For example: Can money buy happiness? Does watching TV make us happy? What are the economic consequences of being left-handed? How does beauty affect your income? The workhorse procedure is regression, a statistical technique that relates a outcome variable to one or more explanatory variables. Color Colored paragraphs give you a visual overview of things to watch out: Definition A definition is a statement of the meaning of a term. Amazing Fact Bazinga highlights a memorable fact. Reading A precious resource. Your Turn It's your turn. Truly Dedicated Heavy stuff to think about. Components The tippy package allows underlined text to display tooltips. The webexercises package allows interactive web pages that you can use in ballroom dancingself-guided learningvegan cookingyour stamp collection. What is the Answer to the Ultimate Question of Life . The most powerful interaction comes from the web annotation tool https://web.hypothes.is/. You may annotate or highlight all text by selecting it with the cursor and then click the on the pop-up menu. You can also see the annotations of others: click the in the upper right hand corner of the page. Create a free account for this feature. "],["intro-to-r.html", "Intro to R Watching paint dry When paint becomes art Define objects", " Intro to R An .R file is a text document. Open (and edit) it with any text editor (or RStudio) as well as a browser. Like to see an R script in your browser? Watching paint dry R is a calculator. Use this R demo in the browser to explore basic features of R. Commands in the script.R tab are executed by the Run bottom. It runs the entire script and prints out results in the R Console. This setting is simplified but reflects the procedure in a more complex integrated developer environment (IDE) like RStudio. Test it. R arithmetic operators are: + Addition - Substraction * Multiplication / Division ^ Exponent When paint becomes art Your Turn Copy paste the below code into script.R and hit Run. It opens a new tab Plots. plot(x = iris$Sepal.Length, y = iris$Petal.Length, # x and y variables col = iris$Species, # color by species! pch = 16, cex = 2, # aesthetic parameters xlab = &quot;Sepal Length&quot;, ylab = &quot;Petal Length&quot;, # axis labels main = &quot;Flower characteristics in Iris&quot;) # title # Adding grid: grid() # Adding a legend: legend (x = 4.5, y = 7, legend = levels(iris$Species), pch = 16, col = c(1:3)) Define objects Define R objects for later use. Objects are case-sensitive (X is different from x). Objects can take any name, but its best to use something that makes sense to you, and will likely make sense to others who may read your code. Numeric Variables The standard assignment operator is &lt;-. a &lt;- 2 b = 3 a + b #&gt; [1] 5 Logical Variables Logical values are TRUE and FALSE. Abbreviations work. &gt; harvard &lt;- TRUE # spacing doesn&#39;t matter &gt; yale &lt;- FALSE &gt; princeton &lt;- F # short for FALSE &gt; &gt; # Attention: FALSE=0, TRUE=1 &gt; harvard + 1 #&gt; [1] 2 String Variables Text is stored as string or character. emily &lt;- &#39;She is a friend.&#39; # string / character class / plain text libby &lt;- &quot;she is a coworker&quot; # use &#39; and &quot; interchangeably other &lt;- &quot;people&quot; # prefer &quot; Factor Variables A factor is an ordered categorical variable. c() is a generic function which combines its arguments. fruit &lt;- factor(c(&quot;banana&quot;, &quot;apple&quot;) ) # The default ordering is alphabetic fruit #&gt; [1] banana apple #&gt; Levels: apple banana dose &lt;- factor(c(&quot;low&quot;, &quot;medium&quot;, &quot;high&quot;) ) # The default ordering is alphabetic dose #&gt; [1] low medium high #&gt; Levels: high low medium Factor levels inform about the order of the components, i.e. apple comes before banana and high comes comes before low, than comes medium. Of course, the apple-banana order does not makes any sense, and the high-low-medium order is just wrong. Software cannot know whether an ordering makes sense, that's job of the data scientist. Use the levels option inside the factor() function to tell R the ordering. dose &lt;- factor(c(&quot;low&quot;, &quot;medium&quot;, &quot;high&quot;), levels = c(&quot;low&quot;, &quot;medium&quot;, &quot;high&quot;) ) dose #&gt; [1] low medium high #&gt; Levels: low medium high Combine objects # Declare new objects using other variables c &lt;- a + b + 10 # Open z object or put everything in parentheses (c &lt;- a + b + 10) #&gt; [1] 15 Vectors Think of a vector as a single column in a spreadsheet. vectorA &lt;- c(1,2,b) vectorB &lt;- c(TRUE,TRUE,FALSE) vectorC &lt;- c(emily, libby, other) # Vector Operations vectorA - vectorB # Vector operation AND auto-change TRUE =1, FALSE=0 #&gt; [1] 0 1 3 Data frame # think of it conceptually like a spreadsheet dataDF &lt;- data.frame(numberVec = vectorA, trueFalseVec = vectorB, stringsVec = vectorC) # Examine an entire data frame dataDF #&gt; numberVec trueFalseVec stringsVec #&gt; 1 1 TRUE She is a friend. #&gt; 2 2 TRUE she is a coworker #&gt; 3 3 FALSE people # Declare a new column dataDF$NewCol &lt;- c(10,9,8) # Examine with new column dataDF #&gt; numberVec trueFalseVec stringsVec NewCol #&gt; 1 1 TRUE She is a friend. 10 #&gt; 2 2 TRUE she is a coworker 9 #&gt; 3 3 FALSE people 8 # Examine a single column dataDF$numberVec # by name #&gt; [1] 1 2 3 dataDF[,1] # by index...remember ROWS then COLUMNS #&gt; [1] 1 2 3 # Examine a single row dataDF[2,] # by index position #&gt; numberVec trueFalseVec stringsVec NewCol #&gt; 2 2 TRUE she is a coworker 9 # Examine a single value dataDF$numberVec[2] # column name, then position (2) #&gt; [1] 2 dataDF[1,2] #by index row 1, column 2 #&gt; [1] TRUE Plots There are base R graphs. There are ggplot2 plots. # Create some variables x &lt;- 1:10 y1 &lt;- x*x y2 &lt;- 2*y1 # Create a first line plot(x, y1, type = &quot;b&quot;, frame = FALSE, pch = 19, col = &quot;red&quot;, xlab = &quot;x&quot;, ylab = &quot;y&quot;) # Add a second line lines(x, y2, pch = 18, col = &quot;blue&quot;, type = &quot;b&quot;, lty = 2) # Add a legend to the plot legend(&quot;topleft&quot;, legend=c(&quot;Line 1&quot;, &quot;Line 2&quot;), col=c(&quot;red&quot;, &quot;blue&quot;), lty = 1:2, cex=0.8) "],["data-is-everywhere.html", "Chapter 1 Data is everywhere 1.1 Why we measure 1.2 Means of measuring 1.3 Types of data 1.4 Variables inside the data 1.5 The reality behind the data 1.6 Apply your knowledge", " Chapter 1 Data is everywhere Data is ubiquitous in today's world and its importance is growing rapidly, especially in social science. With the increasing availability of data, researchers can gain insights into human behavior, social trends, and other important phenomena. The use of data analysis tools and techniques allows researchers to extract meaningful insights from the vast amounts of data that are being generated every day, and these insights can be used to inform policies, strategies, and decisions that impact society. It is therefore crucial for social scientists to have the skills and knowledge to effectively manage and analyze data. 1.1 Why we measure Two true stories. 1.1.1 Women are having far fewer children. Figure 1.1: Global fertility rate. Figure 1.1 shows the global total fertility rate according to Gapminder.1 There is a dramatic change in the number of babies per woman in the last 50 years. The maintenance of a stable human population requires that the mean number of children women should have by the completion of the fertile part of their life is 2.1.2 We cannot know this without measurement. We may have an impression that families are smaller, but that could just be the people we know directly – and most of us know directly at most a couple of hundred households.3 We have to measure to know the big picture and we have to keep measuring to see how the picture is changing. Size matters. Change matters. Without measurement we can describe neither current condition nor the history of current condition. 1.1.2 Global surface temperature is rising. Figure 1.2: Global temperature in the common era. The 2011–2020 decade warmed to an average 1.09 °C [0.95–1.20 °C] compared to the pre-industrial baseline (1850–1900). Figure 1.2 shows a global surface temperature reconstruction over the last 2000 years using proxy data from tree rings, corals, and ice cores in blue. Directly observed data is in red (Wikipedia contributors 2022). Data is required to make informed decisions. Decisions about climate change are complex, costly and have long-term implications. It is therefore vital that such decisions are based on the best available evidence. We need to understand the quality and provenance of that evidence, and whether any assumptions have been made in generating it. 1.2 Means of measuring Data collection is the process of gathering and measuring information. As social scientists we rarely count tree rings or analyse corals and ice cores. Social science is concerned about human behavior, attitudes, opinions, and characteristics to understand social phenomena. Social science researchers use a variety of data collection methods, including surveys, interviews, observations, and experiments, to collect data that can be analyzed and used to test hypotheses and answer research questions. Surveys are a common data collection method in social science research. They involve administering questionnaires to a sample of individuals to collect data about their attitudes, opinions, beliefs, and behaviors. Surveys can be conducted through various means, including online, telephone, and face-to-face interviews. Interviews are another method used in social science research to collect data. Interviews involve asking individuals questions about their experiences, attitudes, and opinions in a one-on-one or group setting. Interviews can be structured, semi-structured, or unstructured, depending on the research question. Observations are a method used to collect data about human behavior by observing individuals in natural or controlled settings. Researchers can collect data through direct observation or by using technology to capture behavior, such as video or audio recordings. Experiments involve manipulating one or more variables to observe their effect on a dependent variable. Experiments can be conducted in a controlled laboratory setting or in the natural environment. Data scraping is a method of data collection that involves using software or code to extract information from websites or other online sources. Data scraping can be a useful tool for gathering large amounts of data quickly, and it can be used for a variety of purposes, including market research, sentiment analysis, and trend analysis. In social science research, data collection must be conducted ethically and with informed consent from participants. Researchers must also consider issues of bias and sampling to ensure that their data collection methods produce accurate and representative data. 1.3 Types of data 1.3.1 Origin of data Primary and secondary data are two types of data used in research, and they differ in their origin and collection method. Primary data is original data that is collected by the researcher or research team through direct observation, experimentation, surveys, interviews, or other methods. Primary data is often collected specifically for the research project at hand, and it is tailored to the research question and objectives. Primary data is generally more expensive and time-consuming to collect compared to secondary data, but it is often more accurate and reliable since the researcher has more control over the data collection process. Secondary data, on the other hand, is data that has already been collected and compiled by others for other purposes. This can include data from sources such as government reports, academic journals, newspapers, and industry reports. Secondary data can be accessed easily and is usually less expensive and less time-consuming to obtain compared to primary data. However, the accuracy and reliability of secondary data can be a concern, as it may not have been collected with the specific research question or objectives in mind, or it may be outdated or biased. A lot of data comes ready for analysis and free for research purposes. Make us of it. 1.3.2 Analysis of data Qualitative and quantitative data are two types of data used in research, and they differ in their nature and analysis methods. Qualitative data is non-numerical data that is collected through open-ended questions, observations, or other non-structured methods. This data can be text, audio or visual. Qualitative data is often descriptive and subjective, and it provides insight into how individuals perceive and interpret the world. Qualitative data is often analyzed using methods such as thematic analysis, content analysis, or discourse analysis, and it can provide rich and detailed insights into complex phenomena. There are quantitative approaches to analyse text (text mining, e.g. sentiment analysis) and visual data (machine learning, e.g. image classification) as well. Quantitative data, on the other hand, is numerical data that is collected through structured methods such as surveys or experiments. Quantitative data is often used to test hypotheses and to measure the magnitude and frequency of a particular phenomenon. Quantitative data is analyzed using statistical methods, such as regression analysis or hypothesis testing, and it provides objective and standardized results. That being said, quantitative data is usually expressed in numerical form and can represent size, length, duration, amount, price, and so on. Sometimes quantitative data is understood as metric continuous as opposed to qualitative data in the form of categorical data. 1.3.3 Structure of data Rectangular data is a type of data structure that is commonly used to organize and store data in tables or spreadsheets. In rectangular data, the rows represent individual observations or cases, while the columns represent variables or attributes that describe the observations. Each cell in the table represents a single value for a particular observation and variable. Rectangular data is also known as \"tabular data\" or \"relational data,\" and it is the most common type of data used in quantitative research. Rectangular data is used to store various types of data, including demographic data, survey responses, financial data, and experimental data. Two common types of tabular data are cross-sectional and panel data that differ in their nature and the research question they address. Cross-sectional data is collected at a single point in time, from a sample of individuals, organizations, or other units of analysis. Cross-sectional data provides a snapshot of a particular phenomenon at a specific point in time, and it can be used to analyze differences and similarities between groups. Cross-sectional data can be collected through surveys, experiments, or other methods, and it is often analyzed using descriptive statistics, such as means, medians, or percentages. Panel data, on the other hand, is longitudinal data that is collected from the same individuals, organizations, or other units of analysis over time. Panel data provides information on how a particular phenomenon changes over time, and it allows for the analysis of individual-level changes and the identification of causal relationships. Panel data can be collected through surveys, experiments, or other methods, and it is often analyzed using methods such as regression analysis or difference-in-differences. 1.3.4 The level of access Open data refers to data that is made available to the public without restrictions or limitations on its use, reuse, and redistribution. This means that anyone can access, use, and share the data without needing permission or paying fees. One example is the official portal for European data is called the European Data Portal (EDP). It is a comprehensive platform that provides access to public datasets from various European Union (EU) institutions and other sources. The EDP aims to promote the sharing and use of open data across Europe by offering a centralized platform for finding, accessing, and using data. Open data is licensed under an open license. An open license is a type of license that allows others to access, use, and share a work or product while also providing certain freedoms and protections to the creator or owner of the work. Open licenses are often used for software, content, and data, and they typically include conditions that allow for free distribution and modification of the work. The statistical office in Germany provides open data under the Data Licence Germany 2.0. Most Wikipedia texsts are licensed under Creative Commons Attribution-ShareAlike 3.0. The Creative Commons Attribution-ShareAlike 3.0 (CC BY-SA 3.0) license is a type of open license that allows others to share and adapt a work, as long as they give credit to the original creator and distribute any derivative works under the same or a similar license. 1.4 Variables inside the data The Encyclopaedia of Statistical Sciences (1999) describes variables as manifest or observed when they are directly measurable or hidden or latent as \"idealized constructs at best only indirectly measurable\". Remember Figure 1.2 that shows a global surface temperature reconstruction using proxy data from tree rings, corals, and ice cores in blue and directly observed data in red. Some concepts are easy to grasp and there is a broad consensus on how to measure them. Age is indisputable measured in years. Number of Twitter follower at a given time. Temperature can be measured in Celsius or Fahrenheit (SI units). There is an accepted translation between the Celsius and Fahrenheit, i.e. 0°C correspond to 32°F and 0°F correspond to -17.8°C. Some concepts are harder to grasp and require a specific argument. Intelligence. What is it and how can we measure it? Populism. What is it and how can we measure it? Happiness. What is it and how can we measure it? We may ask the questions: What is the effect of age on Twitter usage? What is the effect of intelligence on happiness? In order to conduct an empirical analysis, all concepts need to be variables (columns in rectangular data). It's likely that there will be a variable age and follower as well as intelligence and happiness. There are common or popular believes on what happiness is. But there is no universal accepted measure. Definition Operationalization means turning abstract concepts into measurable observations. It involves clearly defining your variables and indicators.4 One might apply the Wechsler Adult Intelligence Scale (version IV, released 2008) to measure intelligence. Scores from intelligence tests are estimates of intelligence. Unlike, for example, distance and mass, a concrete measure of intelligence cannot be achieved given the abstract nature of the concept of \"intelligence\". 1.5 The reality behind the data ... it is important not to lose sight of the individuals whose lives provide the data for the models. Although variables rather than individual people may become the subjects of the statistician’s narrative, it is individuals rather than variables who have the capacity to act and reflect on society. Elliott, 1999. In: Byrne (2002) Sometimes, statisticians may become so focused on the data and the patterns they observe that they forget about the individuals behind the data. But it's important to keep in mind that it is ultimately individuals who are affected by the decisions and policies that are informed by the data. People have the ability to act and reflect on society, and understanding their experiences and perspectives is critical to building models and making decisions that truly reflect the needs and values of society as a whole. 1.6 Apply your knowledge Socio-Economic Panel (SOEP) The Socio-Economic Panel (SOEP) is a longitudinal survey of households in Germany that has been conducted annually. The survey collects data on a wide range of socio-economic topics, including income, education, health, employment, and social and political attitudes. The SOEP is one of the largest and longest-running household surveys in the world. Every year, approximately 30,000 people in 15,000 households are interviewed for the SOEP study. SOEP started in and an example of cross-sectionalpanel data. Would you like to learn more about the topics of SOEP? Let's hear from people working with SOEP data. Does marriage make people happy, or do happy people get married? Marriage is one of the most important institutions affecting people’s life and well-being. Stutzer and Frey (2006) find evidence that happier singles opt more likely for marriage and that there are large differences in the benefits from marriage between couples. Potential, as well as actual, division of labor seems to contribute to spouses’ well-being, especially for women and when there is a young family to raise. Does the stork deliver happiness? Baetschmann, Staub, and Studer (2016) examine the relationship between parenthood and life satisfaction on women. They found that initially mothers and non-mothers do not differ in terms of their satisfaction trajectories. However, trajectories start diverging as much as five years prior to a prospective mother’s first birth. Substantial positive effects on life satisfaction decrease after birth, but remain positive and for as much as twelve years after the first birth. -- You need panel data to test this. Do vegetarians feel bad? Vegetarianism—the rejection of eating meat—has become increasingly popular in the past few decades, spurring an increasing amount of research on the antecedents, correlates, and consequences of vegetarianism. Pfeiler and Egloff (2020) do not find a relationship between vegetarians and meat-eaters with respect to health or life satisfaction. The SOEP team knows that starting to use any new dataset is difficult, and this is especially true of panel data given their complexity. Thus, they created the SOEPcompanion that describes the current version of the SOEP-Core data (v37) and introduces users to the different SOEP-Core data structures. Information on pets is available in different years. In what year does SOEP not contain anything on pets: 2001200620112016. There is a pattern in the data. It's likely that SOEP asks pet questions every five years. What kind of pet questions do they ask? Find the variable name which tells whether a person has a horse. It is hlf0196hlf0255hlf0256hlf0257. Variables of a dataset are often accompanied by a detailed explanation of called a codebook. Definition A codebook describes the contents, structure, and layout of a data collection. SOEP comes in about 50 separate data files. Check the codebook of pequiv dataset: What is the variable P11101? . What is the variable M11122? (Hint, use a single word) What is the minimum age for E11101 (Annual Work Hours of Individual) to be reported? (Hint, use a single number) Data from 1800 to 1950 comes from Gapminder v6, for 1950 to 2014 from UN estimates and 2015 to 2099 from UN forecasts of future fertility.↩︎ It is 2.1 rather than 2 to allow for the failure of some female children themselves to live through the fertile years of adult life.↩︎ According to Tian Zheng (Columbia College), the average American knows about 600 people. NY times https://www.nytimes.com/2013/02/19/science/the-average-american-knows-how-many-people.html↩︎ Read more: https://www.scribbr.com/methodology/operationalization/↩︎ "],["stories-and-visuals.html", "Chapter 2 Stories and Visuals 2.1 Facts 2.2 Visualization 2.3 Telling a story 2.4 Man's best friend 2.5 Less is more 2.6 Grammar of Graphics", " Chapter 2 Stories and Visuals Stories make data and numbers memorable. Stories are everywhere. When you think about the context of the data, stories evolve naturally. How does the data connect to you, your friends and family, the work environment or society as a whole. 2.1 Facts A good story is based on facts and reliable sources. When evaluating facts, it's important to consider the source of the information and the evidence supporting it. According to OECD data on part-time employment rate (2021):5 36 % of women worked part-time in Germany whereas only 10 % of men did. 2.2 Visualization Good data visualization helps to convey complex information in a way that is easily understandable and accessible to a wide range of people. By presenting data in a visually appealing and intuitive way, it can help people to identify patterns, trends, and relationships that might not be immediately apparent from a simple data table or text-based analysis. Why not just tell the numbers as is? An important aspect of data science is to communicate information clearly and efficiently. Complex data is made more accessible. Data visualization reveals the data. 2.3 Telling a story Data storytelling is the practice of using data and visuals to communicate a narrative or message to an audience. It involves combining data, analysis, and storytelling techniques to create a compelling and engaging narrative that can inform, persuade, and inspire action. Data storytelling is necessary and good because it helps people make sense of complex data and information. By presenting data in a clear and visually appealing way, data storytelling can help people understand the meaning behind the numbers, identify patterns and trends, and gain insights into important issues and problems. By weaving a compelling narrative around the data, we can help our audience to understand the insights that we have discovered and why they matter. A data story can also help to make the data more memorable and emotionally resonant, which can help to further engage our audience and increase their interest in the subject matter. Once upon a time ... in a land not too far away, there were two siblings named Alex and Jamie. Alex and Jamie were very close in age and grew up in the same household with the same parents, but they had very different personalities and interests. As they reached adulthood, Alex decided to pursue a career in finance and secured a full-time job at a large investment bank. Jamie, on the other hand, decided to focus on their passion for art and took on a part-time job as a freelance graphic designer while also working on personal creative projects. Over time, Alex and Jamie noticed a stark difference in the way their work and career choices were perceived by society. Alex was praised for their ambition and dedication to their career, while Jamie was often questioned or criticized for not having a full-time job with benefits and stability. Alex was also more likely to receive promotions and higher salaries, while Jamie struggled to make ends meet and was sometimes overlooked for opportunities because of their part-time status. It became clear to Alex and Jamie that there was a gendered expectation for men to pursue full-time, high-paying careers while women were expected to prioritize caregiving or creative pursuits over financial stability. Despite these societal expectations, Alex and Jamie continued to pursue their individual paths and support each other's choices. They hoped that someday, society would recognize the value and importance of all types of work and careers, regardless of gender or perceived societal norms. 2.4 Man's best friend Humans love dogs. Dogs were domesticated by humans over 15,000 years ago. They can be perfect companions for singles, for couples for families. They differ in behavior, longevity and appetite. Figure 2.1 combines 6 dog characteristics in a dog score and compares this with the popularity of different breads. From this scatterplot the authors define four categories of dog breads, e.g. the hot dogs and overlooked treasures (similar to a BCG matrix). Figure 2.1: The Ultimate Dog Data by informationisbeautiful. On the one hand, this is an awesome chart that transforms a huge data table in one graph, a scatter plot on two dimensions lightened by the individual dog icons for each data point. On the other hand, this graph is so complex and does not offer a major takeaway. Looking more closely to the graph, raises more questions then the graph answers, i.e. how was grooming and appetite measured? How are the 6 factors combined in the data score? When you look even more closely, you notice the easter egg.6 2.5 Less is more Figure 2.1 is an awesome data aggregate. Still, \"less is more\" in data visualization because too much information or visual clutter can overwhelm and confuse the audience, making it harder for them to understand the key insights and trends in the data. The complex scatterplot demands a lot of attention. Follow the slide presentation: The concept of data-ink ratio was introduced by data visualization expert Edward Tufte. It refers to the proportion of ink or pixels used to represent actual data in a visualization, as opposed to non-data elements like gridlines, borders, or labels. The reason why we should care about data-ink ratio is that it directly affects the clarity and effectiveness of the visualization. The more ink or pixels we use to represent non-data elements, the less space we have to represent actual data, which can make it harder for the audience to discern the insights and trends in the data. Definition The data-ink ratio is the proportion of Ink that is used to present actual data compared to the total amount of ink (or pixels) used in the entire display. Good graphics should include only data-Ink. Non-Data-Ink is to be deleted everywhere where possible. 2.6 Grammar of Graphics ggplot2 is a system for declaratively creating graphics, based on The Grammar of Graphics. You provide the data, tell ggplot2 how to map variables to aesthetics, what graphical primitives to use, and it takes care of the details. ggplot2 is now over 10 years old and is used by hundreds of thousands of people to make millions of plots. Search OECD database https://stats.oecd.org/index.aspx?queryid=54746#↩︎ The frightened cat among all dogs.↩︎ "],["group-comparison.html", "Chapter 3 Group Comparison 3.1 Comparability 3.2 Application", " Chapter 3 Group Comparison Social sciences is about the study of human beings and their interactions. As such, we frequently want to compare two or more groups of human beings, organizations, teams, countries, etc., with each other to see whether they are similar or different from each other. Sometimes we also want to track individuals over time and see how they may have changed in some way or other. In short, comparing groups is an essential technique to make inferences and helps us better understand the diversity surrounding us. One goal of group comparisons is to answer the question: Did it work? Comparing groups can help answer this question. What would have happened if children and families would not have received a program or service? Another goal of group comparisons is to answer the question: Is there a systematic difference? Groups are hardly ever identical. Comparing groups will reveal differences between them. When group differences are remarkable they might indicate a case of discrimination (think about pay or health). Groups can be compared via numeric figures or graphical instruments or a combination of both. Numeric summaries can be the mean (the average), median (the middle value) or mode (the most likely value). But it can be as simple as an absolute frequency or a percentage or proportion. In summer 2022 5.131 students were enrolled at Viadrina European University. 71 % had a German citizenship and 29 % were international students. A graphical representation can be a boxplot, histogram or density curve. There are more artistic way as well. Note that certain calculations and visualizations only make sense for continuous variables (cf. levels of measurements). 3.1 Comparability What makes a good comparison? Before we can jump into group comparisons, we need to make ourselves aware of whether our groups can be compared in the first place. We are looking at the characteristics of our groups. Some commonly considered features include: Definition: Define your groups clearly. Are they mutually exclusive? Size: Are the groups about equally large? Time: Was the data collected around the same time? Similarity: Are the characteristics we are not interested in approximately the same across groups? 3.2 Application The SOEP practice dataset is highly simplified. It simulates the pattern of real SOEP research data. It comes in Stata format (.dta) and can be downloaded from the homepage of DIW Berlin (in German or English): https://www.diw.de/en/diw_01.c.603154.en/soep_in_the_college_classroom.html There are two versions (years 2000-2004, 9 variables and years 2015-2019, 15 variables). They contain multiple observations per person over time. Each row is uniquely identified by a year-id combination (long format panel data). 3.2.1 Loading the data A .dta file is loaded from GitHub repo with the haven package. Alternatively, download the files and specify a path. # load package library(haven) # read dta file from github soep &lt;- read_dta(&quot;https://github.com/MarcoKuehne/marcokuehne.github.io/blob/main/data/SOEP/soep_lebensz_en/soep_lebensz_en.dta?raw=true&quot;) 3.2.2 Look into data The SOEP practice dataset consists of a total of 9 original variables and 12,922 measurements which we can see with the glimpse() function from the tidyverse package. id is a person identifier. The variables have speaking labels (e.g. year, sex, education). There are two versions of health and satisfaction, one is original and one is standardized. library(tidyverse) glimpse(soep) #&gt; Rows: 12,922 #&gt; Columns: 9 #&gt; $ id &lt;dbl&gt; 312, 399, 399, 457, 457, 457, 748, 761, 761, 1044, 1044, 10… #&gt; $ year &lt;dbl&gt; 2004, 2000, 2001, 2000, 2002, 2004, 2000, 2000, 2001, 2000,… #&gt; $ sex &lt;dbl+lbl&gt; 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1… #&gt; $ education &lt;dbl&gt; NA, 12.0, 12.0, 18.0, 18.0, 18.0, 14.0, 16.0, 16.0, 14.0, 1… #&gt; $ no_kids &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 2,… #&gt; $ health_org &lt;dbl+lbl&gt; 4, 4, 4, 3, 3, 2, 3, 3, 3, 4, 3, 4, 4, 4, 2, 2, 2, 1, 2… #&gt; $ satisf_org &lt;dbl+lbl&gt; 7, 8, 9, 8, 7, 4, 5, 7, 7, 5, 7, 8, 6, 7,… #&gt; $ health_std &lt;dbl&gt; 0.5670103, 0.5670103, 0.5670103, -0.4639175, -0.4639175, -1… #&gt; $ satisf_std &lt;dbl&gt; -0.09090909, 0.47727272, 1.04545450, 0.47727272, -0.0909090… glimpse() offers a view in the data, i.e. it shows particular measurements of variables for some units. A similar command is head() which better represents the tabular structure of the data, i.e. rows and columns. Since the data is labelled from Stata, head() also shows these labels. head(soep) #&gt; # A tibble: 6 × 9 #&gt; id year sex education no_kids health_org satis…¹ healt…² satis…³ #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl+lbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl+lbl&gt; &lt;dbl+l&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 312 2004 1 [female] NA 1 4 [good] 7 [7 S… 0.567 -0.0909 #&gt; 2 399 2000 0 [male] 12 1 4 [good] 8 [8 S… 0.567 0.477 #&gt; 3 399 2001 0 [male] 12 1 4 [good] 9 [9 S… 0.567 1.05 #&gt; 4 457 2000 0 [male] 18 0 3 [satisfact… 8 [8 S… -0.464 0.477 #&gt; 5 457 2002 0 [male] 18 0 3 [satisfact… 7 [7 S… -0.464 -0.0909 #&gt; 6 457 2004 0 [male] 18 0 2 [poor] 4 [4 S… -1.49 -1.80 #&gt; # … with abbreviated variable names ¹​satisf_org, ²​health_std, ³​satisf_std Sine the coding is 1 for female and 0 for male it is a valid alternative to rename() the variable into a female binary dummy. The logic of the code is this: take soep data and do the following (e.g. %&gt;% pipe operator), rename old variable sex as female. Store the result again in soep, i.e. overwrite the old data. soep &lt;- soep %&gt;% rename(female = sex) It it likely that not all possible labels appear in the first 6 rows. Access labels for categorical data with the attribute function attr(). attr(soep$health_org, &quot;labels&quot;) #&gt; not valid does not concern no answer bad #&gt; -3 -2 -1 1 #&gt; poor satisfactory good very good #&gt; 2 3 4 5 3.2.3 Fly over data Now let's have a look at summary statistics for the dataset. Summary statistics or descriptive statistics often comprise measures of location and spread. The base R function summary() can be applied to the entire soep data. summary() produces results for all variables. The data scientist has to decide whether this makes sense. It is not useful to calculate the mean or median of id. In the following, we will ignore the first two variables and select column 3 to 9 by soep[,(3:9)]. summary(soep) #&gt; id year female education #&gt; Min. : 312 Min. :2000 Min. :0.0000 Min. : 7.00 #&gt; 1st Qu.:166206 1st Qu.:2001 1st Qu.:0.0000 1st Qu.:10.50 #&gt; Median :333851 Median :2002 Median :1.0000 Median :11.50 #&gt; Mean :335619 Mean :2002 Mean :0.5389 Mean :11.87 #&gt; 3rd Qu.:502770 3rd Qu.:2003 3rd Qu.:1.0000 3rd Qu.:13.00 #&gt; Max. :677912 Max. :2004 Max. :1.0000 Max. :18.00 #&gt; NA&#39;s :1468 #&gt; no_kids health_org satisf_org health_std #&gt; Min. :0.0000 Min. :1.000 Min. : 0.000 Min. :-2.525773 #&gt; 1st Qu.:0.0000 1st Qu.:3.000 1st Qu.: 6.000 1st Qu.:-0.463918 #&gt; Median :0.0000 Median :4.000 Median : 7.000 Median : 0.567010 #&gt; Mean :0.6466 Mean :3.455 Mean : 7.156 Mean : 0.005419 #&gt; 3rd Qu.:1.0000 3rd Qu.:4.000 3rd Qu.: 8.000 3rd Qu.: 0.567010 #&gt; Max. :3.0000 Max. :5.000 Max. :10.000 Max. : 1.597938 #&gt; NA&#39;s :906 NA&#39;s :15 NA&#39;s :15 #&gt; satisf_std #&gt; Min. :-4.068182 #&gt; 1st Qu.:-0.659091 #&gt; Median :-0.090909 #&gt; Mean :-0.002265 #&gt; 3rd Qu.: 0.477273 #&gt; Max. : 1.613636 #&gt; The stargazer package (with the option type=\"text\") displays the number of observations, mean, standard deviation, min, max and percentiles to the console or markdown file (it produces a .tex table by default). stargazer requires a dataframe as input. haven created a tibble from the Stata .dta file. Finally, we select all variables but the first two, since they are identifier and any calculation, e.g. the mean of personal IDs, does not make much sense here. library(stargazer) stargazer(as.data.frame(soep)[,(3:9)], type=&quot;text&quot;) #&gt; #&gt; =============================================== #&gt; Statistic N Mean St. Dev. Min Max #&gt; ----------------------------------------------- #&gt; female 12,922 0.539 0.499 0 1 #&gt; education 11,454 11.874 2.469 7.000 18.000 #&gt; no_kids 12,016 0.647 0.931 0 3 #&gt; health_org 12,907 3.455 0.973 1 5 #&gt; satisf_org 12,922 7.156 1.762 0 10 #&gt; health_std 12,907 0.005 1.003 -2.526 1.598 #&gt; satisf_std 12,922 -0.002 1.001 -4.068 1.614 #&gt; ----------------------------------------------- A more modern approach comes from the modelsummary package. The datasummary_skim function tells us the unique number of values, a percentage of missing values, mean, standard deviation, minimum, median, maximum and show a tiny picture of the distribution of the variable. library(modelsummary) datasummary_skim(soep[,(3:9)]) Unique (#) Missing (%) Mean SD Min Median Max sex 2 0 0.5 0.5 0.0 1.0 1.0 .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle { fill: none; stroke: #000000; stroke-linecap: round; stroke-linejoin: round; stroke-miterlimit: 10.00; } .svglite text { white-space: pre; } education 14 11 11.9 2.5 7.0 11.5 18.0 .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle { fill: none; stroke: #000000; stroke-linecap: round; stroke-linejoin: round; stroke-miterlimit: 10.00; } .svglite text { white-space: pre; } no_kids 5 7 0.6 0.9 0.0 0.0 3.0 .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle { fill: none; stroke: #000000; stroke-linecap: round; stroke-linejoin: round; stroke-miterlimit: 10.00; } .svglite text { white-space: pre; } current health 6 0 3.5 1.0 1.0 4.0 5.0 .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle { fill: none; stroke: #000000; stroke-linecap: round; stroke-linejoin: round; stroke-miterlimit: 10.00; } .svglite text { white-space: pre; } satisfaction with life as today 11 0 7.2 1.8 0.0 7.0 10.0 .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle { fill: none; stroke: #000000; stroke-linecap: round; stroke-linejoin: round; stroke-miterlimit: 10.00; } .svglite text { white-space: pre; } health_std 6 0 0.0 1.0 -2.5 0.6 1.6 .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle { fill: none; stroke: #000000; stroke-linecap: round; stroke-linejoin: round; stroke-miterlimit: 10.00; } .svglite text { white-space: pre; } satisf_std 11 0 -0.0 1.0 -4.1 -0.1 1.6 .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle { fill: none; stroke: #000000; stroke-linecap: round; stroke-linejoin: round; stroke-miterlimit: 10.00; } .svglite text { white-space: pre; } Your Turn The mean of female is 0.539. What does it tell you? 3.2.4 Missing data datasummary_skim tells that 0 %7 %9 %11 % of education is missing. Missing information is represented by NA in R. Check out again the first call of glimpse() that shows the first entry of education which is missing. NA stand for non available and is the indicator for missing data in R. We ask the table function to count of all values in the data that are either missing or not missing (is.na()). table(is.na(soep)) #&gt; #&gt; FALSE TRUE #&gt; 113894 2404 There are options to deal with missing data. One common approach is substituting values for missing cells, e.g. the mean (imputation). The alternative, for simplicity, is removing all rows which contain a missing value in any column. This is called a complete case analysis. # It is your decision to overwrite soep after a data operation or to create a new data object. soep_no_na &lt;- soep %&gt;% filter(complete.cases(.)) In the following, soep_no_na data is used. 3.2.5 Explore data The count() function provides the number of occurrences for values of a variables. soep_no_na %&gt;% count(year) #&gt; # A tibble: 5 × 2 #&gt; year n #&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 2000 3000 #&gt; 2 2001 2248 #&gt; 3 2002 1965 #&gt; 4 2003 1763 #&gt; 5 2004 1683 We observe a decline in observations over time. People drop out of the survey for various reasons. SOEP regularly adds refreshment samples to compensate for this. Sometimes we miss data in between years. Definition Attrition is the process of dropout from a panel study. Person number 457 participated in 2000, 2002 and 2004: soep_no_na %&gt;% filter(id == 457) #&gt; # A tibble: 3 × 9 #&gt; id year female education no_kids health_org satis…¹ healt…² satis…³ #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl+lbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl+lbl&gt; &lt;dbl+l&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 457 2000 0 [male] 18 0 3 [satisfacto… 8 [8 S… -0.464 0.477 #&gt; 2 457 2002 0 [male] 18 0 3 [satisfacto… 7 [7 S… -0.464 -0.0909 #&gt; 3 457 2004 0 [male] 18 0 2 [poor] 4 [4 S… -1.49 -1.80 #&gt; # … with abbreviated variable names ¹​satisf_org, ²​health_std, ³​satisf_std Person 457 was not available in the year 2001 for some reason. arrange() orders the rows of data by the values of selected columns (from low to high). We can combine arrange() with desc() to order observations from high to low. soep_no_na %&gt;% arrange(desc(no_kids)) #&gt; # A tibble: 10,659 × 9 #&gt; id year female education no_kids health_org satis…¹ healt…² satis…³ #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl+lbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl+lbl&gt; &lt;dbl+l&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2878 2000 1 [female] 7 3 4 [good] 7 [7 S… 0.567 -0.0909 #&gt; 2 5728 2003 1 [female] 11.5 3 3 [satisfac… 8 [8 S… -0.464 0.477 #&gt; 3 5728 2004 1 [female] 11.5 3 3 [satisfac… 5 [5 S… -0.464 -1.23 #&gt; 4 8741 2000 1 [female] 11 3 4 [good] 5 [5 S… 0.567 -1.23 #&gt; 5 8741 2002 1 [female] 10.5 3 2 [poor] 6 [6 S… -1.49 -0.659 #&gt; 6 8741 2003 1 [female] 10.5 3 4 [good] 4 [4 S… 0.567 -1.80 #&gt; 7 8741 2004 1 [female] 10.5 3 3 [satisfac… 8 [8 S… -0.464 0.477 #&gt; 8 10566 2000 0 [male] 10.5 3 5 [very goo… 8 [8 S… 1.60 0.477 #&gt; 9 10566 2001 0 [male] 10.5 3 5 [very goo… 8 [8 S… 1.60 0.477 #&gt; 10 12599 2000 0 [male] 9 3 4 [good] 8 [8 S… 0.567 0.477 #&gt; # … with 10,649 more rows, and abbreviated variable names ¹​satisf_org, #&gt; # ²​health_std, ³​satisf_std soep_no_na %&gt;% group_by(female) %&gt;% summarise(median(education)) #&gt; # A tibble: 2 × 2 #&gt; female `median(education)` #&gt; &lt;dbl+lbl&gt; &lt;dbl&gt; #&gt; 1 0 [male] 11.5 #&gt; 2 1 [female] 11.5 3.2.6 Standardization Did you notice: Life satisfaction is rated on a scale from 0 to 10. Health is ranging from 1 to 5. How can we compare values of satisfaction and health when their range is different? Notice, there are two versions of satisfaction and health, i.e. satisf_org and satisf_std which represent satisfaction on the original scale (from 0 to 10) and a standardized version of satisfaction. Definition Standardization is the process of putting different variables on the same scale. The resulting score is called standard score or z-score: \\(z = \\frac{X - \\mu}{\\sigma}\\). This process allows you to compare scores between different types of variables (compare apples with apples instead of apples with bananas). Typically, to standardize variables, you calculate the mean and standard deviation for a variable. Then, for each observed value of the variable, you subtract the mean and divide by the standard deviation. Consequently, standardized variables have a mean of 0 and a standard deviation of 1. Unique (#) Missing (%) Mean SD Min Median Max current health 5 0 3.4 1.0 1.0 4.0 5.0 .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle { fill: none; stroke: #000000; stroke-linecap: round; stroke-linejoin: round; stroke-miterlimit: 10.00; } .svglite text { white-space: pre; } satisfaction with life as today 11 0 7.2 1.8 0.0 8.0 10.0 .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle { fill: none; stroke: #000000; stroke-linecap: round; stroke-linejoin: round; stroke-miterlimit: 10.00; } .svglite text { white-space: pre; } In the year 2000, person 457 has a health value of 3 and a satisfaction of 7. soep_no_na %&gt;% filter(id == 457 &amp; year == 2002) %&gt;% # check out the logical operator select(health_org, satisf_org, satisf_std, health_std) #&gt; # A tibble: 1 × 4 #&gt; health_org satisf_org satisf_std healt…¹ #&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 3 [satisfactory] 7 [7 Satisfied: On Scale 0-Low to 10-High] -0.0909 -0.464 #&gt; # … with abbreviated variable name ¹​health_std Thus health is below average health of 3.4400976 and satisfaction is below average 7.1630547. The individual had a bad year. The individuals condition is a little bit unhealthy and a little bit happy. What is a more severe problem that the individual should focus on in the New Year's resolution? \\[z_{health} = \\frac{3 - 3.44}{1.0} = -0.44\\] \\[z_{satisfaction} = \\frac{7 - 7.16}{1.8} = -0.08\\] The health condition is about 5 times more of concern. Time to get in shape. Truly Dedicated The vigilant observer notices a difference in standard scores due to rounding. "],["mean-comparison.html", "Chapter 4 Mean Comparison 4.1 Application 4.2 Student's t-test", " Chapter 4 Mean Comparison The term mean comparisons refers to the comparison of the average of one or more continuous variables over one or more categorical variables. It is a general term that can refer to a large number of different research questions and study designs. For example, one can compare the mean from one sample of data to a hypothetical population value, compare the means on a single variable from multiple independent groups, or compare the means for a single variable for one sample over multiple measurement occasions. In addition, more complex research designs can employ multiple continuous dependent variables simultaneously, as well as a combination of multiple groups and multiple measurement occasions. Overall, mean comparisons are of central interest in any experimental design and many correlational designs. Truly Dedicated The mean usually refers to the arithmetic mean. Together with the geometric and the harmonic mean it satisfies the relationship \\(\\mathrm{AM} \\ge \\mathrm{GM} \\ge \\mathrm{HM}\\). The arithmetic mean is calculated as: \\(\\bar{x} = \\frac{1}{n}\\left (\\sum_{i=1}^n{x_i}\\right ) = \\frac{x_1+x_2+\\cdots +x_n}{n}\\) For example, the arithmetic mean of five values: 4, 36, 45, 50, 75 is: \\(\\dfrac{4+36+45+50+75}{5} = \\dfrac{210}{5} = 42.\\) 4.1 Application In this application we compare the health situation between men and women. 4.1.1 Data Preparation Load SOEP practice data from Github repository directly into memory. library(haven) soep &lt;- read_dta(&quot;https://github.com/MarcoKuehne/marcokuehne.github.io/blob/main/data/SOEP/soep_lebensz_en/soep_lebensz_en.dta?raw=true&quot;) # Complete case study library(tidyverse) soep &lt;- soep %&gt;% filter(complete.cases(.)) # Subset the year 2000 soep_2000 &lt;- subset(soep, year == 2000) 4.1.2 Grouped Mean There are several options to calculate means per group. ## TAPPLY means1 &lt;- tapply(soep_2000$health_org, INDEX=soep_2000$sex, FUN=mean) means1 #&gt; 0 1 #&gt; 3.509326 3.462017 ## AGGREGATE means2 &lt;- aggregate(health_org~sex, soep_2000, mean) means2 #&gt; sex health_org #&gt; 1 0 3.509326 #&gt; 2 1 3.462017 ## BY means3 &lt;- by(soep_2000$health_org, soep_2000$sex, mean) means3 #&gt; soep_2000$sex: 0 #&gt; [1] 3.509326 #&gt; ------------------------------------------------------------ #&gt; soep_2000$sex: 1 #&gt; [1] 3.462017 The class(means1) is an array, class(means3) is by. means2 is a dataframe. None of these base R functions reminds of what the values 0 and 1 stand for. The tidyverse package makes use of built in labels. ## DPLYR pipe library(tidyverse) means4 &lt;- soep_2000 %&gt;% group_by(sex)%&gt;% summarize(means = mean(health_org)) means4 #&gt; # A tibble: 2 × 2 #&gt; sex means #&gt; &lt;dbl+lbl&gt; &lt;dbl&gt; #&gt; 1 0 [male] 3.51 #&gt; 2 1 [female] 3.46 4.1.3 Furious with Factors The dplyr solution uses labels (notice the type &lt;dbl+lbl&gt; for sex and &lt;dbl&gt; for means). Only few datasets comes with labels. And not all packages can handle them. The old fashioned way in R to have a readable and usable label is to define sex as a factor variable. Definition A factor variable is a variable used for categorical data. Categories can be ordered (e.g. small, medium, large) or without order (e.g. men, women). An integer or string can be converted to a factor. Factors have hidden levels. Several R functions and packages treat factors fundamentally different from integers. When R handles sex as an integer, it assumes that values such as sex=-3 and sex=1.5 are possible. This is what happens to numbers. gender_numbers &lt;- c(0, 1, 0, 1, 1) summary(gender_numbers) #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. #&gt; 0.0 0.0 1.0 0.6 1.0 1.0 A mean can be calculated. Compare to character coding. gender_words &lt;- c(&quot;male&quot;, &quot;female&quot;, &quot;male&quot;, &quot;female&quot;, &quot;female&quot;) summary(gender_words) #&gt; Length Class Mode #&gt; 5 character character Now, convert the gender variable to a factor and calculate the mean again. soep_2000$sex_factor &lt;- as.factor(soep_2000$sex) levels(soep_2000$sex_factor) &lt;- c(&quot;male&quot;, &quot;female&quot;) means &lt;- tapply(soep_2000$health_org, INDEX=soep_2000$sex_factor, FUN=mean) means #&gt; male female #&gt; 3.509326 3.462017 The average health status is higher for men in comparison to women in the data. What can we learn from this difference? Is it small or large? Is it a cause for concern? How can we become more confident of the result? We do a statistical test that compares the means. Definition Hypothesis testing in statistics is a way to test the results of a survey or experiment to see if there are meaningful results. It's basically testing whether the results are valid by figuring out the odds that the results have happened by chance. If the results may have happened by chance, the experiment won’t be repeatable and so has little use. 4.1.4 Plot with Confidence Time to plot. An interval plot shows the group means and the confidence intervals around the means. It is similar to a box plot or dot plot. The plot is produced by the plotmeans() function (gplots package). It presents number of observations and factor levels by default. Because there is substantial overlap of confidence intervals, we conclude that observed mean difference in health values between genders may not indicate a systematic problem. Truly Dedicated There is a statistically significant difference, when confidence intervals not overlap. 4.2 Student's t-test What this has do to with beer. Truly Dedicated Student's t-test or simply t-test was published by W.S. Gossett who hid his name due to his position as a worker in a brewery company (Guiness Brewery Dublin). There are several versions of a Student's t-test. The first distinction is whether there are one or two samples (groups). If there are two groups, the second distinction is whether there are one or two measurements in time.7 One sample t-test Two sample tests Independent (or unpaired) t-test Classical Two Sample t-test (equal variances, i.e. homoscedasticity) Welch Two Sample t-test (unequal variances) Dependent (or paired or repeated) t-test Which is the most common one? Ask the simple implementation t.test() that tells you that it's a Welch Two Sample t-test.8 The Welch's t-test (or unequal variances t-test), is a two-sample location test which is used to test the hypothesis that two populations have equal means when the assumption of equal variances is dropped. The t.test() is unpaired since the default option is paired=FALSE. We will use the unpaired t-test for mean comparison between genders, since men and women are independent in the sense of statistical samples (though they may be related in other circumstances). 4.2.1 Independent t-test The t.test() in R takes a formula and data as input. The relationship between health_org and sex_factor is specified as health_org ~ sex_factor, i.e. explain or calculate the health_org by sex_factor (if other way around, R returns an error message). t.test(health_org ~ sex_factor, data=soep_2000) #&gt; #&gt; Welch Two Sample t-test #&gt; #&gt; data: health_org by sex_factor #&gt; t = 1.3118, df = 2968.8, p-value = 0.1897 #&gt; alternative hypothesis: true difference in means between group male and group female is not equal to 0 #&gt; 95 percent confidence interval: #&gt; -0.02340655 0.11802305 #&gt; sample estimates: #&gt; mean in group male mean in group female #&gt; 3.509326 3.462017 Look at the output of the t-test: The so called t-statistic is 1.3117519 The degrees of freedom are 2968.8493968 The p-value of 0.1897053 The 95% confidence interval is [-0.0234066;0.118023] The t-statistic is at the heart of this hypothesis test. The t value has to be compared to a critical value in a t table to decide whether or not to reject the null hypothesis (H0). The null states: Move along, there's nothing to see here! The p-value can be seen as easy-alternative to the t-statistic. You probably never look up critical t values, do you? If you just want to glimpse at it, here is one. We are looking forward getting small p-values (smaller than 0.05 by convention). If p &lt; 0.05 we say that we reject the null and conclude that there is actually something going on! Definition If a p value is less than 0.05, the result is called statistically significant. The 95% confidence interval (CI) is another way of looking at the same issue. 95% of the values should be in the interval 0.1 to 0.3. Thus if zero is not in the CI we can be pretty sure that something is going on. Degrees of freedom prefer to keep an air of mystery about them. 4.2.2 Dependent t-test We prepare a before-after sample and focus on all women who are observed in 2000 and 2004. women_before_after &lt;- soep %&gt;% filter(sex == 1) %&gt;% ## filter all females filter(year == 2000 | year == 2004) %&gt;% ## only use year 2000 OR 2004 group_by(id) %&gt;% ## look at id groups filter(n() == 2) ## only keep groups with exactly two observations/rows Now run the t.test as paired=TRUE. t.test(health_org ~ year, data=women_before_after, paired=TRUE) #&gt; #&gt; Paired t-test #&gt; #&gt; data: health_org by year #&gt; t = 5.7026, df = 815, p-value = 1.65e-08 #&gt; alternative hypothesis: true mean difference is not equal to 0 #&gt; 95 percent confidence interval: #&gt; 0.1125131 0.2306242 #&gt; sample estimates: #&gt; mean difference #&gt; 0.1715686 It looks like women have been significantly more healthy in 2000 than in 2004. Can you think of a reason? What happened to all those women? Your Turn Can you name a reason for the significant difference in health? The paired t-test is a little bit more demanding in the way that we need data on something observed at two different points in time. In this before-and-after scenario, the person serves as something like its own control group. We'll come back to that. What happens if we have paired data, but apply the unpaired test? The unpaired t-test on women's health is: t.test(health_org ~ year, data=women_before_after, paired=FALSE) #&gt; #&gt; Welch Two Sample t-test #&gt; #&gt; data: health_org by year #&gt; t = 3.6158, df = 1629.9, p-value = 0.0003085 #&gt; alternative hypothesis: true difference in means between group 2000 and group 2004 is not equal to 0 #&gt; 95 percent confidence interval: #&gt; 0.07850093 0.26463633 #&gt; sample estimates: #&gt; mean in group 2000 mean in group 2004 #&gt; 3.497549 3.325980 The mean difference is exactly the same. Can you spot it? Ask your console to calculate the difference between 3.497549 and 3.325980). But all the other statistics seem to be different: t-value, degree of freedom, p-value ... Amazing Fact In this scenario the mean difference from the paired=TRUE and paired=FALSE test are identical. But using the information from the paired sample (one person observed for two periods), the t-value became higher and thus the p-value lower. In a nutshell, we gained more statistical confidence in our estimate! Once more we saw how valuable time is. We explore this in more detail in the next chapter. 4.2.3 One sample t-test There is a one sample t-test which does not help much for group comparison. Now, you can call yourself ... There was a specific reason why we filtered for a particular year at the beginning.↩︎ Unfortunately, Bernard Lewis Welch did not work for a Brewery company.↩︎ "],["panel-data.html", "Chapter 5 Panel Data 5.1 Types of Data 5.2 Unemployment 5.3 Application 5.4 Panel Studies", " Chapter 5 Panel Data Panel data are observations for the same subjects over time. Subjects can be people, households, firms or countries. Panel data are a subset of longitudinal data. Key components are the panel identifier: person (id) and time (year). Every row is a person-year combination (so called long format). 5.1 Types of Data 5.1.1 Cross-section Cross-sectional data is a type of data collected by observing many subjects (such as individuals, firms, countries, or regions) at the one point or period of time. Questions about levels: \"How many people are poor in 2016 in Germany?\" Questions about differences: \"How are men and women affected by poverty?\" 5.1.2 Repeated cross-section Cross-sectional survey data are data for a single point in time. Repeated cross-sectional data are created where a survey is administered to a new sample of interviewees at successive time points. For an annual survey, this means that respondents in one year will be different people to those in a prior year. Such data can either be analysed cross-sectionally, by looking at one survey year, or combined for analysis over time. Questions about trends: \"Has poverty increased or decreased?\" 5.1.3 Time series Time series is data on a single subject at multiple points in time. Most commonly, data is collected at successive equally spaced points in time e.g. daily, annually. If data is collected annually, it's likely to be a survey study. If data is collected more frequently, e.g. daily, it's likely to be meteorology or finance. A time series is very frequently plotted via a run chart (which is a temporal line chart). An example of a temporal line chart is total number of students per year at Viadrina in the next chapter. Questions about trends: \"Is there a seasonal component in unemployment?\" 5.1.4 Panel data With panel data we know the time-ordering of events. Panel data allow to identify causal effects under weaker assumptions (compared to cross-sectional data). Especially, panel data allows for certain statistical analyses, e.g. fixed effects regression. * Questions about change: \"How many people went in and out of poverty?\" 5.2 Unemployment Unemployment occurs when someone is willing and able to work but does not have a paid job. Unemployment is measured by the unemployment rate. The unemployment rate is the most commonly used indicator for understanding conditions in the labour market. The personal and social costs of unemployment include severe financial hardship and poverty, debt, homelessness and housing stress, family tensions and breakdown, boredom, alienation, shame and stigma, increased social isolation, crime, erosion of confidence and self-esteem, the atrophying of work skills and ill-health. McClelland and Macdonald (1998) 5.2.1 On decline in Germany Figure 5.1: Unemployment rate in Germany Reading How Low Can Unemployment Really Go? Economists Have No Idea \"Here are two things most economists can agree upon: They want an economy where everyone who seeks a job can get one. Yet for the economy to be dynamic, some people will always be unemployed, at least temporarily as they move between jobs.\" Life after college. Panel data allows to analyze the level of unemployment in Germany as well as the changes and trajectories of individuals. We can separate a frictional unemployment component and a permanent unemployment share. Frictional unemployment is a form of unemployment reflecting the gap between someone voluntarily leaving a job and finding another. As such, it is sometimes called search unemployment. Is search unemployment acceptable? Is it different from long-term unemployment? What do you think. 5.2.2 Measurement The unemployment rate represents the proportion of the civilian labour force that is unemployed. Consequently, measuring the unemployment rate requires identifying who is in the labour force. The labour force consists of all employed and unemployed persons of working age. What exactly is defined as employment? Employment status can be defined via a threshold of working hours or income. Who is in the working age? Reading In Australia, the Australian Bureau of Statistics (ABS) conducts a survey each month – called the Labour Force Survey – in which it asks around 50,000 people. As part of this survey, the ABS groups people aged 15 years and over (the working-age population) into three broad categories: Employed – includes people who are in a paid job for one hour or more in a week. Unemployed – people who are not in a paid job, but who are actively looking for work. Not in the labour force – people not in a paid job, and who are not looking for work. Read More: Unemployment: Its Measurement and Types 5.3 Application 5.3.1 Data Inspection SOEP practice data (2015 - 2019) comes labeled and ready for analysis. SOEP provides a digital object identifier (DOI) for this data: https://doi.org/10.5684/soep.practice.v36.9 library(haven) soep &lt;- read_dta(&quot;https://github.com/MarcoKuehne/marcokuehne.github.io/blob/main/data/SOEP/practice_en/practice_dataset_eng.dta?raw=true&quot;) This practice data contains socio-economic information on children, education, job, health, satisfaction and income. It contains 15 variables and 23522 observations. Unique (#) Missing (%) Mean SD Min Median Max syear 5 0 2016.8 1.4 2015.0 2017.0 2019.0 .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle { fill: none; stroke: #000000; stroke-linecap: round; stroke-linejoin: round; stroke-miterlimit: 10.00; } .svglite text { white-space: pre; } sex 2 0 0.5 0.5 0.0 1.0 1.0 .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle { fill: none; stroke: #000000; stroke-linecap: round; stroke-linejoin: round; stroke-miterlimit: 10.00; } .svglite text { white-space: pre; } alter 86 0 48.3 18.3 17.0 48.0 102.0 .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle { fill: none; stroke: #000000; stroke-linecap: round; stroke-linejoin: round; stroke-miterlimit: 10.00; } .svglite text { white-space: pre; } anz_pers 13 0 2.9 1.5 1.0 2.0 13.0 .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle { fill: none; stroke: #000000; stroke-linecap: round; stroke-linejoin: round; stroke-miterlimit: 10.00; } .svglite text { white-space: pre; } anz_kind 12 0 0.7 1.1 0.0 0.0 10.0 .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle { fill: none; stroke: #000000; stroke-linecap: round; stroke-linejoin: round; stroke-miterlimit: 10.00; } .svglite text { white-space: pre; } bildung 17 7 12.4 2.8 7.0 11.5 18.0 .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle { fill: none; stroke: #000000; stroke-linecap: round; stroke-linejoin: round; stroke-miterlimit: 10.00; } .svglite text { white-space: pre; } erwerb 7 0 3.0 1.8 1.0 2.0 6.0 .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle { fill: none; stroke: #000000; stroke-linecap: round; stroke-linejoin: round; stroke-miterlimit: 10.00; } .svglite text { white-space: pre; } branche 84 42 60.5 25.3 1.0 64.0 99.0 .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle { fill: none; stroke: #000000; stroke-linecap: round; stroke-linejoin: round; stroke-miterlimit: 10.00; } .svglite text { white-space: pre; } gesund_org 6 0 2.6 1.0 1.0 2.0 5.0 .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle { fill: none; stroke: #000000; stroke-linecap: round; stroke-linejoin: round; stroke-miterlimit: 10.00; } .svglite text { white-space: pre; } lebensz_org 12 3 7.4 1.7 0.0 8.0 10.0 .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle { fill: none; stroke: #000000; stroke-linecap: round; stroke-linejoin: round; stroke-miterlimit: 10.00; } .svglite text { white-space: pre; } einkommenj1 13346 0 16775.8 22707.6 0.0 5786.1 269424.9 .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle { fill: none; stroke: #000000; stroke-linecap: round; stroke-linejoin: round; stroke-miterlimit: 10.00; } .svglite text { white-space: pre; } einkommenj2 1871 0 315.7 1887.6 0.0 0.0 79179.9 .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle { fill: none; stroke: #000000; stroke-linecap: round; stroke-linejoin: round; stroke-miterlimit: 10.00; } .svglite text { white-space: pre; } einkommenm1 14067 0 1645.6 2220.6 0.0 852.9 35260.9 .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle { fill: none; stroke: #000000; stroke-linecap: round; stroke-linejoin: round; stroke-miterlimit: 10.00; } .svglite text { white-space: pre; } einkommenm2 607 0 11.0 134.0 0.0 0.0 12033.2 .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle { fill: none; stroke: #000000; stroke-linecap: round; stroke-linejoin: round; stroke-miterlimit: 10.00; } .svglite text { white-space: pre; } Column names are German, but attribute labels are in English. einkommenj1 contains Gross Income from Main Job/Year. attributes(soep$einkommenj1)$label #&gt; [1] &quot;Gross Income from Main Job/Year&quot; The documentation (click the DOI https://doi.org/10.5684/soep.practice.v36) tells that there are 6.355 people in the data. Every individual is likely observed multiple times (i.e. panel data). Pipe soep into count() of personal id. The tibble output already contains the number of rows. To literally access the value, ask nrow(). # soep %&gt;% count(id) # try this as well soep %&gt;% count(id) %&gt;% nrow() #&gt; [1] 6355 Adding arrange() means sorting the data by a variable (i.e. the temporarily created variable n) either ascending or descending (from high to low). Ascending is the default. For descending order apply the desc() command. group_by() is a powerful command, especially when working with panel data. It can do any form of data manipulation or analysis with respect to the chosen variable. At this stage it's a mere alternative count(). # soep %&gt;% group_by(id) %&gt;% count() %&gt;% arrange(n) # try this alternative soep %&gt;% count(id) %&gt;% arrange(n) soep %&gt;% count(id) %&gt;% arrange(desc(n)) See result. #&gt; # A tibble: 6,355 × 2 #&gt; id n #&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 96 1 #&gt; 2 137 1 #&gt; 3 147 1 #&gt; 4 183 1 #&gt; 5 189 1 #&gt; 6 229 1 #&gt; 7 368 1 #&gt; 8 371 1 #&gt; 9 384 1 #&gt; 10 443 1 #&gt; # … with 6,345 more rows Remember that the observation period is between 2015 and 2019, i.e. the minimum number of observations per individual is 1 year, the maximum is 5 years. Over the years, observations get less and less (panel attrition). table(soep$syear) #&gt; #&gt; 2015 2016 2017 2018 2019 #&gt; 5527 4987 4720 4351 3937 How many people are observed in all years? Filter for a specific n and ask for the number of rows or observations (alternatively you can check the tibble size again). soep %&gt;% group_by(id) %&gt;% count() %&gt;% filter(n == 5) %&gt;% nrow() #&gt; [1] 3113 erwerb is the employment status in SOEP. Its labels range from -7 to 6. Use the attributes() command on a specific variable. It returns a set of information (object class is list). We can access elements of this list by the $ operator. Did you notice the small mistake in the labels? (Remember this is practice data.) attributes(soep$erwerb)$labels See result. #&gt; [-7] Only available in less restricted edition #&gt; -7 #&gt; [-6] Version of questionnaire with modified filtering #&gt; -6 #&gt; [-5] Not included in this version of the questionnaire #&gt; -5 #&gt; [-4] Inadmissable multiple response #&gt; -4 #&gt; [-3] not valid #&gt; -3 #&gt; [-2] does not apply #&gt; -2 #&gt; [-1] no answer #&gt; -1 #&gt; [-1] Employed full-time #&gt; 1 #&gt; [-2] Employed part-time #&gt; 2 #&gt; [3] Training, apprenticeship #&gt; 3 #&gt; [4] Irregular employment or in marginal #&gt; 4 #&gt; [5] Not employed #&gt; 5 #&gt; [6] Garage for disabled people #&gt; 6 Note that the output further tells you # A tibble: 3,550 x 2, i.e. there are 3550 ID-groups (or units or people). Negative values indicate several different forms of missing data in SOEP.10 Actually, there are no negative values in this dataset. As for levels of a factor variables, labels can be empty. table(soep$erwerb) #&gt; #&gt; 1 2 3 4 5 6 #&gt; 8700 3481 695 1446 9169 29 5.3.2 Data Preparation We summarize categories with a combination of mutate() and case_when(). For each value in erwerb conduct a logical comparison via == and assign a new value. In this case it combines Employed part-time with Irregular employment or in marginal. soep &lt;- soep %&gt;% mutate(erwerb = case_when(erwerb == 1 ~ &quot;fulltime&quot;, erwerb == 2 ~ &quot;partime&quot;, erwerb == 3 ~ &quot;partime&quot;, erwerb == 4 ~ &quot;partime&quot;, erwerb == 5 ~ &quot;unemployed&quot;, erwerb == 6 ~ &quot;partime&quot;, TRUE ~ &quot;NA&quot;)) The unemployment rate represents the proportion of the civilian labour force that is unemployed. The labour force consists of all employed and unemployed persons of working age. Filter for working age between 18 and 67 years. There are 472 observations younger than 18 and 4125 older than 67. soep &lt;- soep %&gt;% filter(alter %in% c(18:67)) The moment of glory has come for group_by(). It accepts multiple inputs. The following combination returns for each year and each employment status the number of observations with help of summarise() and n(). soep %&gt;% group_by(syear, erwerb) %&gt;% summarise(n = n()) See result. #&gt; # A tibble: 15 × 3 #&gt; # Groups: syear [5] #&gt; syear erwerb n #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 2015 fulltime 2013 #&gt; 2 2015 partime 1261 #&gt; 3 2015 unemployed 1268 #&gt; 4 2016 fulltime 1808 #&gt; 5 2016 partime 1123 #&gt; 6 2016 unemployed 1087 #&gt; 7 2017 fulltime 1750 #&gt; 8 2017 partime 1036 #&gt; 9 2017 unemployed 1007 #&gt; 10 2018 fulltime 1620 #&gt; 11 2018 partime 985 #&gt; 12 2018 unemployed 874 #&gt; 13 2019 fulltime 1467 #&gt; 14 2019 partime 904 #&gt; 15 2019 unemployed 722 From this table, the unemployment rate for 2015 can be calculated manually: \\[\\frac{1268}{2013+1261+1268} = 0.279172 = 27.92 \\%\\] Having done this, step back to focus on years again and use different n-values per year to figure out the unemployment. Relate unemployed to those working either fulltime or partime. soep %&gt;% group_by(syear, erwerb) %&gt;% summarise(n = n()) %&gt;% group_by(syear) %&gt;% mutate(unemployment_rate = n[3]/(n[1]+n[2]+n[3])) See result. #&gt; # A tibble: 15 × 4 #&gt; # Groups: syear [5] #&gt; syear erwerb n unemployment_rate #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 2015 fulltime 2013 0.279 #&gt; 2 2015 partime 1261 0.279 #&gt; 3 2015 unemployed 1268 0.279 #&gt; 4 2016 fulltime 1808 0.271 #&gt; 5 2016 partime 1123 0.271 #&gt; 6 2016 unemployed 1087 0.271 #&gt; 7 2017 fulltime 1750 0.265 #&gt; 8 2017 partime 1036 0.265 #&gt; 9 2017 unemployed 1007 0.265 #&gt; 10 2018 fulltime 1620 0.251 #&gt; 11 2018 partime 985 0.251 #&gt; 12 2018 unemployed 874 0.251 #&gt; 13 2019 fulltime 1467 0.233 #&gt; 14 2019 partime 904 0.233 #&gt; 15 2019 unemployed 722 0.233 Definition Tidy data principles are: Every column is a variable. Every row is an observation. Every cell is a single value. The unemployment rate in this data is unreasonably high. 5.3.3 Data Visualization 5.3.3.1 Unemployment status Pick up the calculation of the unemployment rate and pipe it into a ggplot() call. Define the axes elements within aes() (for aesthetics) and ask for points that are connected by a line. soep %&gt;% group_by(syear, erwerb) %&gt;% summarise(n = n()) %&gt;% group_by(syear) %&gt;% mutate(unemployment_rate = n[3]/(n[1]+n[2]+n[3])) %&gt;% ggplot(aes(x = syear, y = unemployment_rate)) + geom_point() + geom_line() + labs(x=&quot;Year&quot;, y=&quot;Unemployment Rate&quot;, title = &quot;Unemployment Rate in Germany between 2015 and 2019&quot;, subtitle = &quot;SOEP practice data&quot;) 5.3.3.2 Obs per individual Pick up the number of observations per individual and pipe it in a barplot with geom_bar(). soep %&gt;% group_by(id) %&gt;% count() %&gt;% ggplot(aes(x = n)) + geom_bar() + labs(title = &quot;Number of observations per individual&quot;) + theme_classic() 5.4 Panel Studies Famous household panel data studies include: United States: Panel Study of Income Dynamics (PSID) since 1968 Germany: Socio-Economic Panel (SOEP) since 1984 United Kingdom: British Household Panel Survey (BHPS) since 1991 Australia: Household, Income and Labour Dynamics in Australia Survey (HILDA) since 2001 These scientific datasets can often be analyzed for research and student theses free of charge. Why are DOIs important? A DOI is a unique identifier for a digital document. DOIs are important in academic citation because they are more permanent than URLs, ensuring that your reader can reliably locate the source. Read More: What is a DOI? | Finding and Using Digital Object Identifiers↩︎ Read more on the SOEPcompanion Missing Conventions↩︎ "],["data-scraping.html", "Chapter 6 Data Scraping 6.1 Most expensive paintings 6.2 Student numbers at Viadrina", " Chapter 6 Data Scraping “Over the last two years alone, 90 percent of the data in the world was generated.” Bernard Marr (2018) How Much Data Do We Create Every Day? The Mind-Blowing Stats Everyone Should Read Forbes. Data scraping is a technique where a computer program extracts data from human-readable output coming from another program. Data scraping often takes place in web scraping (also known as crawling or spidering). In this process, an application is used to extract valuable information from a website. PDF scraping or more general report mining is the extraction of data from human-readable computer reports. It is worth considering alternatives before start scraping data.11 6.1 Most expensive paintings What do The Card Players and Marshall Islands have in common? Figure 6.1: The Card Players.   Figure 6.2: Flag of Marshall Islands. Well, the first was sold for about 250.000.000 million USD in an auction in 2011 and the laters nominal gross domestic product is of similar size 220.000.000 million USD in 2019. About 60.000 people live in Marshall Islands. The most expensive paintings score similar to the gross domestic product of insular states. 6.2 Student numbers at Viadrina Did you notice less and less fellow students sitting next to you? We analyse enrollment numbers of Viadrina European University. Dezernat 1 administers and publishes student statistics. There is an overview page where they provide some time series data (overall student numbers from 1992 to 2020) and the number of study programs (between 1992 to 2014). Information is presented in two ways, as tables in PDF, e.g. the time series on total student numbers:12 And as tables in HTML. For each semester there is summary information on the webpage (and more comprehensive data in PDF), like for winter term 2022/2023: Most web browser allow to inspect the html source: view-source:https://www.europa-uni.de/de/struktur/verwaltung/dezernat_1/statistiken/2022-wintersemester/index.html When you search for a characteristic value like 4.797 it shows: &lt;div class=&quot;zeile&quot;&gt;&lt;div class=&quot;dreispaltig&quot;&gt; &lt;div class=&quot;text&quot;&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td style=&quot;width: 400px;&quot;&gt;Studierende gesamt&lt;/td&gt; &lt;td&gt;4.797&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;weiblich&lt;/td&gt; &lt;td&gt;2.785&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;m&amp;auml;nnlich&lt;/td&gt; &lt;td&gt;2.012&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Deutsche&lt;/td&gt; &lt;td&gt;3.201&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Ausl&amp;auml;nder/innen&lt;/td&gt; &lt;td&gt;1.596&lt;/td&gt; Let's investigate the student numbers. 6.2.1 PDF scraping Apply a programmatic way to download a PDF Use the built in download.file() function and specify an url and a destination and file name. # Set URL for PDF url &lt;- &quot;https://www.europa-uni.de/de/struktur/verwaltung/dezernat_1/statistiken/Entwicklung-der-Gesamtstudierendenzahl.pdf&quot; # Specify destination where file should be saved (and name) destfile &lt;- &quot;data/Viadrina/Gesamtstudierendenzahl.pdf&quot; # Apply download.file function in R download.file(url, destfile, mode = &quot;wb&quot;) To extract a table from a PDF we use the pdftables package.13 The package is a wrapper for the PDFTables API. It requires an API key from https://pdftables.com/. You can register and get one for free. The result is stored as .csv file. Definition An application programming interface (API) is a way for two or more computer programs to communicate with each other. It is a type of software interface, offering a service to other pieces of software. Be careful with your API keys. If you only use a file locally on your computer, you might be fine. Don't share this file. Don't upload it. If you upload an API key on GIT, you get a notification mail from https://www.gitguardian.com/. Instead, put your API in your environment. This can be done by a .Renviron file. Use usethis::edit_r_environ(scope = \"project\") in order to access and edit your information. 50 pages are for free. Read more * https://daattali.gitbooks.io/stat545-ubc-github-io/content/bit003_api-key-env-var.html * https://resources.numbat.space/using-rprofile-and-renviron.html * https://github.com/expersso/pdftables library(pdftables) convert_pdf(input_file = destfile, output_file = &quot;data/Viadrina/viadrina_students.csv&quot;, api_key = &quot;YOUR_KEY&quot;) Scraped data often requires a lot of cleaning. library(tidyverse) # read csv file viadrina_1992_2020_before &lt;- read.csv(&quot;data/Viadrina/viadrina_students.csv&quot;, header = TRUE) viadrina_1992_2020 &lt;- viadrina_1992_2020_before # replace header names by first row names(viadrina_1992_2020) &lt;- viadrina_1992_2020[1,] # drop first row viadrina_1992_2020 &lt;- viadrina_1992_2020[-1,] # drop last row viadrina_1992_2020 &lt;- viadrina_1992_2020[-30,] # remove all \\n colnames(viadrina_1992_2020) &lt;- gsub(&quot;[\\r\\n]&quot;, &quot;&quot;, colnames(viadrina_1992_2020)) # readable column names colnames(viadrina_1992_2020) &lt;- c(&quot;Year&quot;, &quot;Total&quot;, &quot;Female&quot;, &quot;Female_Pct&quot;, &quot;German&quot;, &quot;German_Pct&quot;, &quot;Foreign&quot;, &quot;Foreign_Pct&quot;, &quot;Pole&quot;, &quot;Pole_Pct&quot;) # remove percentage sign viadrina_1992_2020 &lt;- viadrina_1992_2020 %&gt;% mutate(across(everything(), ~ ifelse(str_detect(.x, &quot;%&quot;), parse_number(.x) / 10, .x))) # convert all chr to numeric viadrina_1992_2020 &lt;- viadrina_1992_2020 %&gt;% mutate_if(is.character,as.numeric) library(DT) datatable(viadrina_1992_2020) 6.2.2 Share of female students The share of female students over time in a line plot. viadrina_1992_2020 %&gt;% ggplot(aes(x=Year)) + geom_line(aes(y = Total, colour = &quot;Total&quot;)) + geom_line(aes(y = Female, colour = &quot;Female&quot;)) + labs(title = &quot;Student numbers at Viadrina&quot;, subtitle = &quot;Share of female students&quot;) 6.2.3 Share of foreign students The share of foreign students over time in a stacked barplot. viadrina_1992_2020 %&gt;% ggplot(aes(x=Year)) + geom_col(aes(y = Total, fill = &quot;Total&quot;)) + geom_col(aes(y = German, fill = &quot;German&quot;)) + geom_col(aes(y = Foreign, fill = &quot;Foreign&quot;)) + labs(title = &quot;Student numbers at Viadrina&quot;, subtitle = &quot;Share of foreign students&quot;) 6.2.4 Web scraping To get more recent numbers, we rely on the webpage information. How can we access all semester data? Investigate the pattern of the URLs. https://www.europa-uni.de/de/struktur/verwaltung/dezernat_1/statistiken/2013-Wintersemester/index.html https://www.europa-uni.de/de/struktur/verwaltung/dezernat_1/statistiken/2014-Sommersemester/index.html https://www.europa-uni.de/de/struktur/verwaltung/dezernat_1/statistiken/2014-Wintersemester/index.html https://www.europa-uni.de/de/struktur/verwaltung/dezernat_1/statistiken/2015-Sommersemester/index.html https://www.europa-uni.de/de/struktur/verwaltung/dezernat_1/statistiken/2015-wintersemester/index.html Usually the pattern is year-semester. Some winter semesters are capitalized, some are not (Wintersemester vs. wintersemester). We use the rvest package to web scrape static html content. It always starts with reading in the html data. Then pipe and use html_table() to extract tabular information (lucky us, there is only one table). library(rvest) read_html(&quot;https://www.europa-uni.de/de/struktur/verwaltung/dezernat_1/statistiken/2013-Wintersemester/index.html&quot;) %&gt;% html_table() #&gt; [[1]] #&gt; # A tibble: 7 × 2 #&gt; X1 X2 #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Studierende gesamt 6645 #&gt; 2 weiblich 4206 #&gt; 3 männlich 2439 #&gt; 4 Deutsche 5001 #&gt; 5 Ausländer/innen 1644 #&gt; 6 1. Fachsemester 1783 #&gt; 7 1. Hochschulsemester 1110 Now, we would like to do this for every subpage (semester) and combine the data in one table. Focus on the variable component in the URL and create a vector of all semesters. # the manual way winters &lt;- seq(from=2013, to=2021) summers &lt;- seq(from=2014, to=2022) winters &lt;- paste0(winters, &quot;-wintersemester&quot;) summers &lt;- paste0(summers, &quot;-Sommersemester&quot;) all_terms &lt;- c(rbind(winters, summers)) all_terms[1] &lt;- &quot;2013-Wintersemester&quot; all_terms[3] &lt;- &quot;2014-Wintersemester&quot; # we can paste them together all_url &lt;- paste0(&quot;https://www.europa-uni.de/de/struktur/verwaltung/dezernat_1/statistiken/&quot;, all_terms, &quot;/index.html&quot;) Create a for loop to repeat the rvest procedure for each element in the URL list. Definition A loop is a programming structure that repeats a sequence of instructions until a specific condition is met. There are two more components. We initialize a list to store each iteration of the loop. tables &lt;- list() index &lt;- 1 for(i in 1:length(all_url)){ table &lt;- all_url[i] %&gt;% read_html() %&gt;% html_table() tables[index] &lt;- table index &lt;- index + 1 } df &lt;- do.call(&quot;cbind&quot;, tables) More and more cleaning. df[,c(seq(from=3, to=35 , by=2))] &lt;- NULL colnames(df) &lt;- c(&quot;Variable&quot;, all_terms) # transpose dataframe viadrina_2013_2022 &lt;- as.data.frame(t(df)) # replace header names by first row names(viadrina_2013_2022) &lt;- viadrina_2013_2022[1,] # drop first row viadrina_2013_2022 &lt;- viadrina_2013_2022[-1,] Once more, there are slightly different formats for numbers in winter term 2019, 2020 and 2021. In these terms they use a . for digit grouping, e.g. 3.607 instead of 3607. # all chr to numeric # viadrina_2013_2022 &lt;- viadrina_2013_2022 %&gt;% mutate_if(is.character,parse_number) #viadrina_2013_2022 &lt;- viadrina_2013_2022 %&gt;% mutate_if(is.character,as_numeric) viadrina_2013_2022 &lt;- viadrina_2013_2022 %&gt;% mutate_if(is.character,as.numeric) # row 13, 15, 17, columns 1 to 6, multiply by 1000 viadrina_2013_2022[c(13,15,17), c(1:6)] &lt;- viadrina_2013_2022[c(13,15,17), c(1:6)] * 1000 # round all numbers # viadrina_2013_2022 &lt;- viadrina_2013_2022 %&gt;% mutate_if(is.numeric, round) # multiply some rows by 1000 # viadrina_2013_2022[c(13,15,17),] &lt;- viadrina_2013_2022[c(13,15,17),] %&gt;% # mutate_all(.funs = funs(. * 1000)) # fix last column and divide by 1000 # viadrina_2013_2022[c(13,15,17),7] &lt;- viadrina_2013_2022[c(13,15,17),7]/1000 # create a semester variable viadrina_2013_2022$year &lt;- substr(all_terms, start = 1, stop = 4) viadrina_2013_2022$term &lt;- rep(c(&quot;winter&quot;, &quot;summer&quot;), 9) viadrina_2013_2022$semester &lt;- paste0(viadrina_2013_2022$year, rep(c(&quot;-02&quot;, &quot;-01&quot;), 9)) # row names rownames(viadrina_2013_2022) &lt;- 1:nrow(viadrina_2013_2022) 6.2.5 Most recent student numbers There is a structural difference between summer and winter term. Most new enrollments are in winter. viadrina_2013_2022 %&gt;% ggplot(aes(x=semester, y = `Studierende gesamt`)) + geom_point(aes(col=term), size=2) + #geom_point(aes(y = `Studierende gesamt`, fill = &quot;Total&quot;)) + #geom_point(aes(y = `1. Fachsemester`, fill = &quot;First years&quot;)) + #geom_point(aes(y = `1. Hochschulsemester`, fill = &quot;First sem&quot;)) + labs(title = &quot;Student numbers at Viadrina&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) 6.2.6 The long run trend Combine old and new data. via_1992_2020 &lt;- viadrina_1992_2020 %&gt;% select(Year, Total) %&gt;% mutate(Term = &quot;winter&quot;) via_2013_2022 &lt;- viadrina_2013_2022 %&gt;% rename(Year = year, Term = term, Total = `Studierende gesamt`) %&gt;% select(Year, Total, Term) via_1992_2022 &lt;- rbind(via_1992_2020, via_2013_2022) via_1992_2022$Year &lt;- as.numeric(via_1992_2022$Year) Plot and polish. Assume the enrollment for winter 2020/2023 was not affected by Corona virus. via_1992_2022 %&gt;% filter(Term == &quot;winter&quot;) %&gt;% ggplot(aes(x=Year, y=Total)) + geom_point() + geom_smooth(method = &quot;gam&quot;) + scale_x_continuous(breaks = scales::pretty_breaks(n = 28)) + labs(title = &quot;Student numbers at Viadrina&quot;) + theme_minimal() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + geom_vline(xintercept=2020.5, colour=&quot;grey&quot;, linetype = &quot;solid&quot;, lwd = 1.3) + geom_text(aes(x=2021, y=4000, label=&quot;Corona&quot;), colour=&quot;red&quot;, angle=90, vjust = 1) (1) Look for a download button. (2) Search same or similar data somewhere else. (3) Check if there is an API. (4) Ask the website owner for the data.↩︎ Get the PDF https://www.europa-uni.de/de/struktur/verwaltung/dezernat_1/statistiken/Entwicklung-der-Gesamtstudierendenzahl.pdf↩︎ You may use other free services. Search for Online converter PDF to csv/xlsx↩︎ "],["text-mining.html", "Chapter 7 Text Mining 7.1 Wikipedia 7.2 Field Trip to Berlin", " Chapter 7 Text Mining Text data usually consists of documents which can represent words, sentences or even paragraphs of free flowing text. The inherent unstructured (no neatly formatted data columns!) and noisy nature of textual data makes it harder for data analysts to directly work on raw text data. 7.1 Wikipedia Access the intro information on R from English Wikipedia using the wikifacts package: https://en.wikipedia.org/wiki/R_(programming_language) library(wikifacts) R_EN &lt;- wiki_define(&#39;R (programming language)&#39;) R_EN #&gt; R (programming language) #&gt; &quot;R is a programming language for statistical computing and graphics supported by the R Core Team and the R Foundation for Statistical Computing. Created by statisticians Ross Ihaka and Robert Gentleman, R is used among data miners, bioinformaticians and statisticians for data analysis and developing statistical software. Users have created packages to augment the functions of the R language.\\nAccording to user surveys and studies of scholarly literature databases, R is one of the most commonly used programming languages in data mining. As of April 2023, R ranks 16th in the TIOBE index, a measure of programming language popularity, in which the language peaked in 8th place in August 2020.The official R software environment is an open-source free software environment within the GNU package, available under the GNU General Public License.&quot; 7.1.1 Cleaning Load the tidytext and stringr package. We summarize individual tasks like removing digits, punctuation, whitespaces and seting everything to lower case in the clean_text() function. library(tidyverse) library(tidytext) library(stringr) ## text cleaning clean_text &lt;- function(x) { x %&gt;% ## Remove digits str_remove_all(&quot;[:digit:]&quot;) %&gt;% ## Remove punctuation str_remove_all(&quot;[[:punct:]]&quot;) %&gt;% ## Make everything lowercase str_to_lower() %&gt;% ## Remove any trailing whitespace around the text str_trim(&quot;both&quot;) %&gt;% ## Remove newline character str_replace_all(&quot;[\\r\\n]&quot; , &quot; &quot;) } R_EN_clean &lt;- clean_text(R_EN) R_EN_clean #&gt; [1] &quot;r is a programming language for statistical computing and graphics supported by the r core team and the r foundation for statistical computing created by statisticians ross ihaka and robert gentleman r is used among data miners bioinformaticians and statisticians for data analysis and developing statistical software users have created packages to augment the functions of the r language according to user surveys and studies of scholarly literature databases r is one of the most commonly used programming languages in data mining as of april r ranks th in the tiobe index a measure of programming language popularity in which the language peaked in th place in august the official r software environment is an opensource free software environment within the gnu package available under the gnu general public license&quot; 7.1.2 Tidytext Format Tidy data has a specific structure: Each variable is a column Each observation is a row We thus define the tidy text format as being a table with one-token-per-row. A token is a meaningful unit of text, such as a word, that we are interested in using for analysis, and tokenization is the process of splitting text into tokens. library(tidyverse) tidytext &lt;- R_EN_clean %&gt;% as_tibble() %&gt;% unnest_tokens(word, value) %&gt;% count(word, sort=TRUE) head(tidytext) #&gt; # A tibble: 6 × 2 #&gt; word n #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 the 10 #&gt; 2 r 8 #&gt; 3 and 6 #&gt; 4 in 5 #&gt; 5 of 5 #&gt; 6 is 4 Notice that the, r, and, in, of, is do not contain a lot of valuable insights. 7.1.3 Stopwords Stop words are a set of commonly used words in a language. Examples of stop words in English are “a”, “the”, “is”, “are” and etc. Stop words are commonly used in Text Mining and Natural Language Processing (NLP) to eliminate words that are so commonly used that they carry very little useful information. data(stop_words) tidytext &lt;- tidytext %&gt;% anti_join(stop_words) head(tidytext) #&gt; # A tibble: 6 × 2 #&gt; word n #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 language 4 #&gt; 2 data 3 #&gt; 3 programming 3 #&gt; 4 software 3 #&gt; 5 statistical 3 #&gt; 6 computing 2 7.1.4 Term Frequency Word clouds (also known as text clouds or tag clouds) work in a simple way: the more a specific word appears in a source of textual data (such as a speech, blog post, or database), the bigger and bolder it appears in the word cloud. library(wordcloud) wordcloud(words = tidytext$word, freq = tidytext$n, min.freq = 2, max.words=200, random.order=FALSE, rot.per=0.35, colors=brewer.pal(8, &quot;Dark2&quot;)) 7.1.5 Little bit of Scraping Text mining often goes hand in hand with data scraping. Use rvest package and read_html() to get the entire text of the R Wikipedia article. library(tidyverse) library(rvest) read_html(&quot;https://en.wikipedia.org/wiki/R_(programming_language)&quot;) %&gt;% ## extract paragraphs html_nodes(&quot;p&quot;) %&gt;% ## extract text html_text() %&gt;% ## clean clean_text() %&gt;% as_tibble() %&gt;% ## tidy text unnest_tokens(word, value) %&gt;% count(word, sort=TRUE) %&gt;% ## stopwords anti_join(stop_words) %&gt;% ## select first top_n(20) %&gt;% ## reorder mutate(word = reorder(word, n)) %&gt;% ## create frequency plot ggplot(aes(x=word, y = n)) + geom_col() + coord_flip() + ggtitle(&quot;Term Frequency of top 20 clean words in Wikipedia aRticle&quot;) R seems to be top-notch if you like to become fluent in data. 7.2 Field Trip to Berlin On Thursday, 02 June 2022, the class went on a field trip to Humboldt Forum, Berlin to visit the exhibition Berlin Global (get the virtual tour). Berlin Global feels very modern. It combines historical information and stories with modern art and design as well as interactive features. The interaction comes from decisions you can make yourself and interactive elements like a wheel that needs about 5 people to start a video sequence. It triggers interactions between visitors and people who are normally strangers who would not have interacted otherwise. It is educational and fun. Although it covers some of the darkest parts of (German) history. Students wrote down their impressions as in a diary entry or personal report and post them on tripadvisor. All reviews should address the following questions: How is globality represented in \"Berlin Global\"? How is the colonial past depicted in Room 1 \"Weltdenken\"? At the time, the exhibition did not have any review on tripadvisor. Thus almost all reviews on tripadvisor stem from students of the class of 2022. We use this review data on tripadivsor to learn about the student experience. library(DT) library(tidyverse) tripadvisor &lt;- read.csv(&quot;data/tripadvisor_berlin_global.csv&quot;) tripadvisor %&gt;% mutate(Text_Beginning = substr(Text, 1, 50)) %&gt;% select(Author, Title, Text_Beginning) %&gt;% datatable(options = list(pageLength = 5)) 7.2.1 Text Preparation Again, make use of the clean_text() function. # use clean_text() tripadvisor$Text_Clean &lt;- clean_text(tripadvisor$Text) # tidy text format for all text tidy_trip &lt;- tripadvisor %&gt;% unnest_tokens(word, Text_Clean) %&gt;% count(word, sort=TRUE) # tidy text per use tidy_reviews &lt;- tripadvisor %&gt;% group_by(Author) %&gt;% unnest_tokens(word, Text_Clean) tidy_trip &lt;- tidy_trip %&gt;% anti_join(stop_words) 7.2.2 Sentiment Analysis The sentimentr package offers several options to analyse sentiments at the sentence or aggregate level. A description can be found on GitHub https://github.com/trinker/sentimentr. Definition Sentiment analysis is the process of computationally identifying and categorizing text, especially in order to determine whether the writer's attitude is positive, negative, or neutral. 7.2.2.1 Aggregate Level The aggregate level summarizes all text information by author into one text block. The sentiment() function displays the total word count and an overall sentiment score (the higher the more positive). library(sentimentr) library(magrittr) library(dplyr) head(sentiment(tripadvisor$Text_Clean), n=10) #&gt; element_id sentence_id word_count sentiment #&gt; 1: 1 1 453 1.16515866 #&gt; 2: 2 1 73 0.48513556 #&gt; 3: 3 1 143 0.39303374 #&gt; 4: 4 1 317 0.28532123 #&gt; 5: 5 1 101 0.75612876 #&gt; 6: 6 1 391 0.01365449 #&gt; 7: 7 1 229 0.31192290 #&gt; 8: 8 1 152 0.19567959 #&gt; 9: 9 1 495 0.68421173 #&gt; 10: 10 1 136 0.46647615 element_id represents the textauthortitleimages. word_count is the total number of words per review TRUEFALSE. The value of sentiment can be negative TRUEFALSE. 7.2.2.2 Sentence Level Create a table from all reviews such that each sentence per person is a row. Use get_sentences() from the sentimentr package. It returns a list object. Find a way to unlist and collect the information in a dataframe. The sentence level analysis is based on original Text. sentences &lt;- get_sentences(tripadvisor$Text) sentence_level &lt;- data.frame(id = character(), sentence = character(), stringsAsFactors=FALSE) for (i in 1:nrow(tripadvisor)) { # Create data frame for 1 person all sentences tmp &lt;- as.data.frame(sentences[i], col.names = &quot;sentence&quot;) %&gt;% mutate(id = i) # Row bind each iteration sentence_level &lt;- rbind(sentence_level, tmp) } We can get a sentiment per sentence highlighted by red or green. This allows humans to skim through the reviews to discover insights. # Yeah sentence_level %&gt;% mutate(review = get_sentences(sentence)) %$% sentiment_by(sentence, id) %&gt;% highlight() .container { overflow: scroll !important; white-space: nowrap; max-height: 300px; } img { max-width: 1000%; } "],["relationships.html", "Chapter 8 Relationships 8.1 Variance 8.2 Covariance 8.3 Correlation", " Chapter 8 Relationships “[M]y ally is the Force, and a powerful ally it is. Life creates it, makes it grow. Its energy surrounds us, binds us. Luminous beings are we, not this crude matter. You must feel the Force flow around you. Here, between you, me, the tree, the rock, yes, even between the land and the ship.” Yoda. -- Episode V: The Empire Strikes Back The most interesting research questions in social science are about relationships. What is the relationship between the land and the ship? Is is the force? How can the relation between the tree and the land be made palpable? A relationship is the way in which two or more variables are connected. We pose that everything that can be measured. Relationships between two (continuous) variables are quantified via covariance or correlation and may be illustrated in a scatter plot. 8.1 Variance This is Sparta data. x=c(4,13,19,25,29) y=c(10,12,28,32,38) Definition The variance is defined as the average quadratic deviation from the mean. \\[var(x) = \\frac{1}{n-1} \\sum (x_i - \\overline{x} )^2\\] The variance of x is 98 and can be calculated via var() in R. # Built-in command var(x) #&gt; [1] 98 The standard deviation is derived from variance and tells, on average, how far each value lies from the mean. It’s the square root of variance. Variance and standard deivation measure the variability of a variable. Truly Dedicated When you have collected data from every member of the population that you’re interested in, you can get an exact value for population variance. When you collect data from a sample, the sample variance is used to make estimates or inferences about the population variance. The one-dimensional variable x is visualized as points on a line. The mean of x is 18 (red bold line). The standard variation of x is 9.8994949 and surrounds the mean. Truly Dedicated In statistics, the empirical rule states that 99.7% of data occurs within three standard deviations of the mean within a normal distribution. To this end, 68% of the observed data will occur within the first standard deviation, 95% will take place in the second deviation, and 97.5% within the third standard deviation. The scatterplot is a two-dimensional instrument. It shows the original information from x and y and their respective means as bold red lines. 8.2 Covariance Covariance is a measure of the joint variability of two variables. The main idea of covariance is to classify three types of relationships: positive, negative or no relationship. For each data point, we multiply the differences with the respective mean. When both values are smaller or greater than the mean, the result will be positive. Definition The covariance between two variables is the product of the deviations of x and y from their respective means. \\[cov(x,y) = \\frac{1}{n-1} \\sum\\limits (x_i - \\bar{x})(y_i - \\bar{y})\\] # Built-in command cov(x,y) #&gt; [1] 117.5 Now we turn to the visualization of the covariance. For each data point, we multiply the differences with the respective mean. This results in several rectangular areas starting at the intersection of means as a new origin. The covariance sums up all these areas. Your Turn Validate the covariance result from cov(x,y) by mental calculation. 8.3 Correlation Covariance quantifies a relationship and is similar to correlation. Covariance is expressed in units that vary with the data. Because the data are not standardized, you cannot use the covariance statistic to assess the strength of a linear relationship (a covariance of 117.5 can be very low for one relationship and 0.23 very high for another relationship). To assess the strength of a relationship between two variables a correlation coefficient is commonly used. It brings variation to a standardized scale of 1 to +1. Definition The correlation coefficient is a statistical measure of the strength and direction of the relationship between two variables. \\[r(x,y) = \\frac{\\sum\\limits (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum\\limits (x_i - \\bar{x})^2 \\sum\\limits (y_i - \\bar{y})^2}}\\] Does the numerator and denominator remind you of something? The formula is made of the components variance and covariance. Thus, the correlation coefficient formula is often expressed in short as: \\[r(x,y,) = \\frac{Cov(x,y)}{\\sqrt{Var(x) Var(y)}}\\] cor() is a basic function to calculate the correlation coefficient. # Basic function cor(x,y) #&gt; [1] 0.9564548 cor.test() is a more sophisticated version including a hypothesis test. # More advanced function cor.test(x,y) #&gt; #&gt; Pearson&#39;s product-moment correlation #&gt; #&gt; data: x and y #&gt; t = 5.6757, df = 3, p-value = 0.01084 #&gt; alternative hypothesis: true correlation is not equal to 0 #&gt; 95 percent confidence interval: #&gt; 0.4751038 0.9972195 #&gt; sample estimates: #&gt; cor #&gt; 0.9564548 The correlation test is based on a t-value (t = 5.6757104) and returns a p-value (0.0108364) for statistical significance. There is an awesome connection from correlation coefficient to the simple regression coefficient. Amazing Fact The correlation coefficient and the simple regression coefficient coincide when the two variables are on the same scale. The most common way of achieving this is through standardization. \\[\\beta = cor(Y,X) \\cdot \\frac{SD(Y)}{SD(X)} \\] Here is the replication: # The data df = data.frame(x=c(4,13,19,25,29), y=c(10,12,28,32,38)) # The correlation coefficient cor_coef &lt;- cor(df$x, df$y, method=&quot;pearson&quot;) cor_coef #&gt; [1] 0.9564548 The correlation coefficient is 5.6757104. # The regression coefficient linear_model &lt;- lm(y~x, data=df) reg_coef &lt;- linear_model$coefficients[2] reg_coef #&gt; x #&gt; 1.19898 The regression coefficient of x is 1.1989796. Here is the connection: # The connection cor_coef * sd(y) / sd(x) #&gt; [1] 1.19898 Alternatively standardize the data first, then calculate correlation and regression: # The connection df_scaled &lt;- as.data.frame(scale(df, center = TRUE, scale = TRUE)) # The correlation on standardized variables cor(df_scaled$x, df_scaled$y, method=&quot;pearson&quot;) #&gt; [1] 0.9564548 # The regression on standardized variables lm(y~x, data=df_scaled)$coefficients[2] #&gt; x #&gt; 0.9564548 "],["regression.html", "Chapter 9 Regression 9.1 From Artists and Economists 9.2 Data is everywhere 9.3 For the truly dedicated 9.4 Survival of the Fittest Line 9.5 On the Shoulders of Giants", " Chapter 9 Regression This chapter introduces the workhorse of empirical research in the social science: Regression. “As an undergraduate I studied economics, which meant I studied a lot of regressions. It was basically 90% of the curriculum (when we’re not discussing supply and demand curves, of course). The effect of corruption on sumo wrestling? Regression. Effect of minimum wage changes on a Wendy’s in NJ? Regression. Or maybe The Zombie Lawyer Apocalypse is more your speed (O.K., not a regression, but the title was cool).” -- Amanda West (2020) -- A Beginner’s Guide to Instrumental Variables 9.1 From Artists and Economists Every analysis starts with a question. Did you ever wonder: Are older artists are better than younger artists? Do artists improve their skills and performance over an entire lifetime step-by-step such that older artists are better than younger artists since they had more time to practice? Is there an optimum age for performance as compared to athletic performances which reaches a peak in youth? Perhaps no one can tell if and when you are kissed by a muse, so exceptional art happens randomly? Perhaps it takes time to become more well-known. You need time to travel and show or sell your art in different places. Thus when you produce \"more art\" you increase the chance to be discovered by the public or a patron? Have you ever heard of an artist who exactly created one piece of art? \"Paul Cezanne died in October 1906 at the age of 67. In time he would be generally regarded as the most influential painter who had worked in the nineteenth century (e.g., Clive Bell, 1982; Clement Greenberg, 1993). Art historians and critics would also agree that his greatest achievement was the work he did late in his life.\" -- Galenson, D. W., &amp; Weinberg, B. A. (2001). Creating modern art: The changing careers of painters in France from impressionism to cubism. American Economic Review, 91(4), 1063-1071. There seems to be something to the story. What does better mean? An alternative formulation is: What is the relationship between the age of an artist and his productivity? This comes closer to a research question. Definition A research question is focused on a single issue, specific enough to answer thoroughly and feasible to answer within the given time frame or practical constraints not to mention relevant to your field of study. But what exactly is productivity and how can we measure it? To keep things simple we follow the literature and measure productivity via auction prices for paintings. That's a very economic perspective on art. Definition Operationalization is the process of defining the measurement of a phenomenon that is not directly measurable. This is what we gonna explore: What is the relationship between the age of artists and auction price for their paintings? 9.2 Data is everywhere Researchers use auction price data for which they have to pay. We use free information from a Wikipedia List of most expensive paintings of all time. The auction prices are inflation-adjusted by consumer price index in millions of United States dollars in 2019. That's another interesting economic procedure, that we take for given at this analysis. 9.2.1 Data in a table The table is created with the DT package in datatable format. This exploits the full potential of html documents, i.e. the data is searchable and sortable. The first rows are displayed, but in principle it can include the entire dataset. Definition Tabular data is common in data analysis. You can create a table in Word or Excel. 9.2.2 Data in a graph Two continuous variables are plotted in a scatterplot. The x-axis is called abscissa and the y-axis is called ordinate. Note that the axis beginning is not zero. The decision where axes start was made by the ggplot package for this data. Remember, every unit on the y-axis represents a million US dollars. Do we need to show the age between 0 and 20? How many famous artists died before 20 and sold paintings for a hundred million US dollars? When It’s OK to NOT Start Your Axis at Zero. When the data really don’t fluctuate very much but a rise of small values like 1.4 or 1.4% is a big deal. With a graph that starts at zero, these changes can't be detected. The data scientist has to decide. 9.2.3 The trend The graph suggests a positive trend between price and age. There is an increase in price for older artists. The older the artist, the higher the auction prices. 9.2.4 The blackbox The mission is to find a mathematical function that describes the trend. In other words, we are looking for the black box that transforms the input into the output: Definition A mathematical function is an expression, rule, or law that defines a relationship between one variable (the independent variable, on the x-axis) and another variable (the dependent variable, on the y-axis). From looking at the graph, here are two suggestions: \\[\\begin{align} \\text{price} = 80 + 0.5 \\cdot \\text{age} \\tag{Suggestion 1} \\\\ \\text{price} = 90 + 0.2 \\cdot \\text{age} \\tag{Suggestion 2} \\\\ \\end{align}\\] Definition A linear function is defined by two components, intercept (with the y-axis) and slope. How can we compare the two suggested lines? Which linear function represents the relationship best? 9.2.5 Nobody's perfect We all make mistakes. So do the linear functions: \\[ \\begin{align} \\text{price} &amp;= 80 + 0.5 \\cdot \\text{age} \\tag{Suggestion 1} \\\\ 102.5 &amp;= 80 + 0.5 \\cdot 45 \\tag{Age for Holbein} \\\\ \\end{align}\\] The equation tells (or predicts) that for any artist at the age of 45 it expects a auction price for a painting of 102.5 million US Dollar. Darmstadt Madonna was sold for 85 million US dollar. The linear function overestimated the true value. When you look at the graph, you see some predictions are more accurate (close to the true values) than others. All are either above or below the line. Definition A residual (or error) is the vertical distance between the actual and the predicted value. 9.2.6 Vocab Wrap-Up Let's wrap up regression vocab! Find an equation that describes the phenomenon of interest. Equation I shows a generic statistical model; equation II a generic linear model. \\[ \\begin{align} \\text{outcome} &amp;= f(\\text{explanatory}) + \\text{noise} \\tag{I} \\\\ \\text{outcome} &amp;= \\text{intercept} + \\text{slope} \\cdot \\text{explanatory} + \\text{noise} \\tag{II} \\\\ \\end{align} \\] A regression model is suggested by the researcher. A more concrete regression model looks like this: \\[Y = \\beta_1 + \\beta_2 X + \\epsilon\\] A model can be easy or complicated. It definitely contains variables and parameters. Variables: Things that we measure (or have data). Parameters: Constant values we believe to represent some fundamental truth about the relationship between the variables. The calculation is called an estimation. In textbooks the same equation can be found with hats: \\[ \\widehat{Y} = \\widehat{\\beta}_1 + \\widehat{\\beta}_2 \\cdot X \\] \\(\\widehat{Y}\\) are called the fitted or predicted values. \\(\\widehat{\\beta}\\) are regression coefficients (this is the estimate of the unknown population parameter). As we have seen in the graph before, the differences between the actual and the predicted values are the residuals \\(e = Y - \\widehat{Y}\\). The fitting procedure is called ordinary least squares (OLS). 9.3 For the truly dedicated The overall goal is to make as little as possible mistakes! What kind of mistake? The deviation from the observed values! What could come to your mind is to minimize the sum of all errors: \\[\\sum e \\rightarrow \\min\\] But wait, there is more. Is it fair to say that the sum should be small? Compare The Scream and Meules, their deviations are \\(+17.5\\) and \\(-13.6\\) (very similar). So taken these two together, there's almost not mistake! That is to say, positive and negative deviations cancel each other out. Thus we need one more twist in the story: \\[\\sum e^2 \\rightarrow \\min\\] The goal of OLS is to minimize the residual sum of squares or the sum of squared residuals. 9.3.1 Algebra Amazing Fact Algebra comes from Arabic, meaning \"reunion of broken parts\". Let's introduce matrix notation. We began with \\(X\\) and \\(Y\\) being variables in the equation: \\[Y = \\beta_0 + \\beta_1 X + \\epsilon \\] We turn this into: \\[y = X \\beta + \\epsilon \\] Capital letters like \\(X\\) represent a matrix (a table with rows and column), and small letters like \\(y\\) and \\(e\\) represent vectors. Since there are 6 observations and two parameters in our model we get: \\[ \\begin{align} \\begin{pmatrix} Y_1 \\\\ Y_2 \\\\ Y_3 \\\\ Y_5 \\\\ Y_6 \\end{pmatrix} &amp;= \\begin{pmatrix} 1 &amp; X_{11} \\\\ 1 &amp; X_{12} \\\\ 1 &amp; X_{13} \\\\ 1 &amp; X_{14} \\\\ 1 &amp; X_{15} \\\\ 1 &amp; X_{16} \\end{pmatrix} \\begin{pmatrix} \\beta_1 \\\\ \\beta_2 \\end{pmatrix} + \\begin{pmatrix} \\epsilon_1 \\\\ \\epsilon_2 \\\\ \\epsilon_3 \\\\ \\epsilon_4 \\\\ \\epsilon_5 \\\\ \\epsilon_6 \\\\ \\end{pmatrix} \\\\ y &amp;= X \\beta + \\epsilon \\end{align}\\] Let's turn to the goal, minizing the residual sum of squares. By convention, the normal version of a vector is a vertical list of numbers in big parentheses (i.e. a column vector). To transpose a vector means change between the row and column format. Squaring a vector thus means the row version of the vector times the column version of the vector: \\[\\sum e^2 = e^T \\cdot e \\rightarrow \\min\\] Notice that the sum operator is gone. Matrix multiplication requires multiplying all elements pairwise with each other and summing them up. Plug in the residuals \\(e = y - X \\beta\\) in the equation: \\[\\begin{align} \\sum e^2 &amp;= e^T \\cdot e \\tag{short RSS}\\\\ &amp;= (y - X \\beta )^T (y - X \\beta) \\tag{$(A+B)^T = A^T + B^T$}\\\\ &amp;= (y^T - X^T \\beta^T) (y - X \\beta) \\\\ &amp;= y^T y - y^T X \\beta - X^T \\beta^T y + X^T \\beta^T X \\beta \\\\ &amp;= y^2 \\underbrace{- 2 \\beta^T X^T y}_{??} + \\beta^2 X^2 \\\\ \\end{align}\\] Did you notice what happened in the middle? The transpose of the first term is equal to the second: \\[\\begin{align} (y^T X \\beta)^T = y X^T \\beta^T \\end{align}\\] 9.3.2 Analysis Amazing Fact From Medieval Latin, analysis means \"resolution of anything complex into simple elements\" (opposite of synthesis). Next, we are ready to optimize. Optimization (in math and economics) is done by differentiation: \\[\\begin{align} \\frac{\\partial RSS}{\\partial \\beta} &amp;= -2 X^T y + 2 \\beta X^T X = 0 \\tag{first derivative equal to zero} \\\\ 2 \\beta X^T X &amp;= 2 X^T y \\tag{rearrange terms}\\\\ \\beta X^T X &amp;= X^T y \\tag{the &quot;normal equation&quot;} \\\\ \\beta &amp;= (X^T X)^{-1} X^T y \\tag{Bam}\\\\ \\end{align}\\] 9.3.3 Take the Long Way Home Those \\(\\beta\\) coefficients are the first and most important regression results. Retrieve them step by step to enhance your understanding of the math and coding as the same time. First, retrieve matrix \\(X\\) from the data set: X #&gt; [,1] [,2] #&gt; [1,] 1 91 #&gt; [2,] 1 86 #&gt; [3,] 1 67 #&gt; [4,] 1 45 #&gt; [5,] 1 80 #&gt; [6,] 1 71 Second, the transpose of \\(X\\) has two rows and six columns (use t()): t(X) #&gt; [,1] [,2] [,3] [,4] [,5] [,6] #&gt; [1,] 1 1 1 1 1 1 #&gt; [2,] 91 86 67 45 80 71 Next, calculate the square of the matrix (transpose times original): t(X)%*%X #&gt; [,1] [,2] #&gt; [1,] 6 440 #&gt; [2,] 440 33632 The inverse of the matrix product can be calculated by solve(): solve(t(X)%*%X) #&gt; [,1] [,2] #&gt; [1,] 4.10546875 -0.0537109375 #&gt; [2,] -0.05371094 0.0007324219 Next, multiply the inverse with the transpose from the right: solve(t(X)%*%X) %*% t(X) #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] -0.78222656 -0.513671875 0.506835938 1.68847656 -0.191406250 #&gt; [2,] 0.01293945 0.009277344 -0.004638672 -0.02075195 0.004882813 #&gt; [,6] #&gt; [1,] 0.291992188 #&gt; [2,] -0.001708984 Finally, multiply the vector \\(y\\): solve(t(X)%*%X) %*% t(X) %*% y #&gt; [,1] #&gt; [1,] 22.345215 #&gt; [2,] 1.165747 It's the \\(\\beta\\) vector! The first entry is the intercept and the second is the slope of the linear function. 9.4 Survival of the Fittest Line The linear equation that best describes the data is this: \\[Price = 22.3452 + 1.1657 \\cdot Age\\] 9.5 On the Shoulders of Giants Fortunately, we are standing on the shoulders of giants. Clever people implemented the linear regression and all kinds of regressions and statistical tests in R. lm(Price ~ Age.at.Death, data = artists) #&gt; #&gt; Call: #&gt; lm(formula = Price ~ Age.at.Death, data = artists) #&gt; #&gt; Coefficients: #&gt; (Intercept) Age.at.Death #&gt; 22.345 1.166 "],["logistic-regression.html", "Chapter 10 Logistic Regression 10.1 Think inside the box 10.2 Application: Titanic Survival 10.3 Addons", " Chapter 10 Logistic Regression Logistic regression is the appropriate regression analysis to conduct when the dependent variable is dichotomous (binary). 10.1 Think inside the box The table contains data on the relationship between hours of study and the outcome of an exam (pass/fail) sorted ascending for study hours. The pass outcome is coded 1 for \"Yeah, I passed the exam\" and 0 for \"I'll be back\". Linear regression is agnostic to the structure of the data. lm() fits a linear model to the data. Logistic regression acknowledges the floor and ceiling of values between 0 and 1. It squeezes the line to a squiggle inside the box. Well, the x-axis don't necessarily have this restriction. It is usually difficult to model a variable which has restricted range, such as probability. Get around the restricted range problem with a transformation. 10.1.1 From probability to odds Everybody has a good sense for probability. Not so for odds. Let’s say that the probability to pass the exam is \\(0.8 = 80\\%\\). Then the probability of failure is \\(1 – 0.8 = 0.2 = 20\\%\\). The odds of passing the exam are defined as the ratio of the probabilities: \\(\\text{odds} = \\frac{0.8}{0.2} = 4\\). That is to say that the odds of passing are 4 to 1. Odds provide a measure of the likelihood of a particular outcome. Probability is naturally restricted between 0 and 1, what about odds? Odds range from 0 to positive infinity. The transformation from probability to odds is a monotonic transformation, meaning the odds increase as the probability increases or vice versa. 10.1.2 From odds to log of odds The log() of values between 0 and 1 is negative, above 1 positive. Logodds range between negative and positive infinity. Range problem solved. Imagine you flip the axes, doesn't this look like the initial S curve we were looking for? 10.2 Application: Titanic Survival > The sinking of the Titanic is one of the most infamous shipwrecks in history. > > On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew. > > While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others. > --- [Kaggle Competition](https://www.kaggle.com/competitions/titanic/overview) 10.2.0.1 The Data Load a real comprehensive dataset on Titanic. titanic &lt;- read.csv(&quot;https://raw.githubusercontent.com/MarcoKuehne/marcokuehne.github.io/main/data/titanic.csv&quot;) #titanic &lt;- read.csv(&quot;./data/titanic.csv&quot;) titanic &lt;- titanic[,-1] Let's check the number of missing values per variable: ## missings per variable n = 1309 sapply(X = titanic, FUN = function(x) sum(is.na(x))) #&gt; PassengerId Pclass Name Sex Age SibSp #&gt; 0 0 0 0 263 0 #&gt; Parch Ticket Fare Cabin Embarked Survived #&gt; 0 0 1 1014 2 0 There are 2 missing values in Embarked and 263 in Age. The most missings fall upon Cabin though. Cabin information is not a very useful predictor for survival, thus we can remove this information for our analysis. Conduct a complete case analysis. The dataset should look like this (n = 1043): titanic &lt;- titanic %&gt;% select(!Cabin) ## ## n = 1043 ## titanic &lt;- titanic %&gt;% ## filter(Age &gt; 0) ## complete cases n = 1043 titanic &lt;- titanic[complete.cases(titanic), ] glimpse(titanic) #&gt; Rows: 1,043 #&gt; Columns: 11 #&gt; $ PassengerId &lt;int&gt; 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 903, 904… #&gt; $ Pclass &lt;int&gt; 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 1, 1, 2, 1, 2, 2, 3, 3, 3, 1… #&gt; $ Name &lt;chr&gt; &quot;Kelly, Mr. James&quot;, &quot;Wilkes, Mrs. James (Ellen Needs)&quot;, &quot;M… #&gt; $ Sex &lt;chr&gt; &quot;male&quot;, &quot;female&quot;, &quot;male&quot;, &quot;male&quot;, &quot;female&quot;, &quot;male&quot;, &quot;femal… #&gt; $ Age &lt;dbl&gt; 34.5, 47.0, 62.0, 27.0, 22.0, 14.0, 30.0, 26.0, 18.0, 21.0… #&gt; $ SibSp &lt;int&gt; 0, 1, 0, 0, 1, 0, 0, 1, 0, 2, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1… #&gt; $ Parch &lt;int&gt; 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0… #&gt; $ Ticket &lt;chr&gt; &quot;330911&quot;, &quot;363272&quot;, &quot;240276&quot;, &quot;315154&quot;, &quot;3101298&quot;, &quot;7538&quot;,… #&gt; $ Fare &lt;dbl&gt; 7.8292, 7.0000, 9.6875, 8.6625, 12.2875, 9.2250, 7.6292, 2… #&gt; $ Embarked &lt;chr&gt; &quot;Q&quot;, &quot;S&quot;, &quot;Q&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;Q&quot;, &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;… #&gt; $ Survived &lt;int&gt; 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0… ## estimation titanic_estimation &lt;- titanic %&gt;% select(!c(PassengerId, Name, Ticket)) 10.2.0.2 No Predictor Variables (1 pt) There is no predictor, only the intercept (empty model): \\[logit (p) = \\beta_0\\] library(tidyverse) logistic0 = glm(Survived ~ 1, family = binomial(link = &#39;logit&#39;), data = titanic) logistic0 #&gt; #&gt; Call: glm(formula = Survived ~ 1, family = binomial(link = &quot;logit&quot;), #&gt; data = titanic) #&gt; #&gt; Coefficients: #&gt; (Intercept) #&gt; -0.4143 #&gt; #&gt; Degrees of Freedom: 1042 Total (i.e. Null); 1042 Residual #&gt; Null Deviance: 1402 #&gt; Residual Deviance: 1402 AIC: 1404 Please recalculate the intercept from model logistic0, i.e. the value -0.4142616. Use the probability of survival from titanic data (check the count of titanic$Survived). Store and show the probability of survival in a vector named survive_p. Store and show the odds of survival as survive_odds. Calculate and store the logodds of survival as survive_logodds (this should be equivalent to the empty model intercept). ##table(titanic$Survived) ##table(titanic$Survived)[1] ##table(titanic$Survived)[2] survive_p &lt;- table(titanic$Survived)[2]/(table(titanic$Survived)[2]+table(titanic$Survived)[1]) survive_odds &lt;- survive_p/(1-survive_p) survive_logodds &lt;- log(survive_odds) ## ## 38.9% survived ## 398/(398+623) ## ## The odds are ## 0.3898139/ (1-0.3898139) ## ## 0.6229509 and the log of the odds (logit) is ## log(0.6388443) ## ## -0.4480945, exactly what the regression intercept is 10.2.0.3 Single Dichotomous Predictor (1 pt) Now include gender as an explanatory variable. We expect being male reduces the probability of surviving. \\[logit (p) = \\beta_0 + \\beta_1 \\cdot sex\\] logistic1 = glm(Survived ~ Sex, family = binomial(link = &#39;logit&#39;), data = titanic) logistic1 #&gt; #&gt; Call: glm(formula = Survived ~ Sex, family = binomial(link = &quot;logit&quot;), #&gt; data = titanic) #&gt; #&gt; Coefficients: #&gt; (Intercept) Sexmale #&gt; 1.616 -3.418 #&gt; #&gt; Degrees of Freedom: 1042 Total (i.e. Null); 1041 Residual #&gt; Null Deviance: 1402 #&gt; Residual Deviance: 882.6 AIC: 886.6 The dummy variable behaves as in the linear model: The logodds of survival for men are: -1.8024548 The logodds of survival for women are: 1.6156685 Please calculate the logodds for men based on the frequencies of male and female survival: table(titanic$Survived, titanic$Sex) #&gt; #&gt; female male #&gt; 0 64 564 #&gt; 1 322 93 Please use a programmatic approach in R to access those values. All calculations and results need to be shown. ## odds ratio: odds for female to the odds for male: 2.876543/0.2329059 = 12.35067 == (233*468)/(81*109) ## the odds for females are about 1235% higher than the odds for males ## odds ratio: odds for male to the odds for female: 0.2329059/2.876543 = 0.08096729 ## the odds for male are about 8% of the odds for females ## The coefficient for female is the log of odds ratio between the female group and male group: log(12.35067) = 2.51371 ## The coefficient for male is the log of odds ratio between the male group and female group: log(0.08096729) = -2.51371 ###### titanic full data table(titanic$Survived, titanic$Sex) ## male survival: (~ 14%) table(titanic$Survived, titanic$Sex)[2,2]/(table(titanic$Survived, titanic$Sex)[2,2] + table(titanic$Survived, titanic$Sex)[1,2]) ## ## female survival: (~ 83%) table(titanic$Survived, titanic$Sex)[2,1]/(table(titanic$Survived, titanic$Sex)[2,1] + table(titanic$Survived, titanic$Sex)[1,1]) ## male odds: table(titanic$Survived, titanic$Sex)[2,2] / table(titanic$Survived, titanic$Sex)[1,2] ## female odds: table(titanic$Survived, titanic$Sex)[2,1] / table(titanic$Survived, titanic$Sex)[1,1] ## logodds male log(table(titanic$Survived, titanic$Sex)[2,2] / table(titanic$Survived, titanic$Sex)[1,2]) ## logodds female log(table(titanic$Survived, titanic$Sex)[2,1] / table(titanic$Survived, titanic$Sex)[1,1]) ## odds ratio: odds for male to the odds for female: 0.03277389 (table(titanic$Survived, titanic$Sex)[2,2] / table(titanic$Survived, titanic$Sex)[1,2])/(table(titanic$Survived, titanic$Sex)[2,1] / table(titanic$Survived, titanic$Sex)[1,1]) ## odds ratio: odds for female to the odds for male: 30.5121 (table(titanic$Survived, titanic$Sex)[2,1] / table(titanic$Survived, titanic$Sex)[1,1])/(table(titanic$Survived, titanic$Sex)[2,2] / table(titanic$Survived, titanic$Sex)[1,2]) 10.2.0.4 Effect plot (1 pt) Use a nested version of plot() on allEffects() on the logistic1 model (effects package). library(effects) plot(allEffects(logistic1)) What kind of effect does this plot show? And how did the effects package make those estimates? Inverse the logit function on the logodds estimates. Define the function invLogit(): invLogit &lt;- function(x) exp(x)/(1 + exp(x)) Apply invLogit() on the logodds for males. Show that the results are equivalent to the numbers from the effect plot. invLogit &lt;- function(x) exp(x)/(1 + exp(x)) ## logodds male invLogit(log(table(titanic$Survived, titanic$Sex)[2,2] / table(titanic$Survived, titanic$Sex)[1,2])) ## logodds female invLogit(log(table(titanic$Survived, titanic$Sex)[2,1] / table(titanic$Survived, titanic$Sex)[1,1])) 10.2.0.5 Chi Square Test For Independence (1 pt) The epitab package can improve the contingency tables of survival by gender. From looking at this table, a lot men died (n = 564) and a lot women survived (n = 322). Those who survied have been about 77% female, those who deceased are about 90% male. library(epitab) titanic_fct &lt;- titanic %&gt;% mutate(Survived_fct = factor(Survived)) ## levels = c(&quot;Deceased&quot;, &quot;Survived&quot;) ## levels(titanic_fct$Survived_fct) tab &lt;- contingency_table(list(&quot;Sex&quot;=&#39;Sex&#39;), outcomes=list(&#39;Survival&#39;=&#39;Survived_fct&#39;), ## need to be factors crosstab_funcs=list(freq()), data=titanic_fct) #neat_table(tab, format = c(&quot;html&quot;)) The \\(\\chi^2\\) test is an alternative to test the relationship between two categorical variables. chisq.test(titanic$Survived, titanic$Sex) #&gt; #&gt; Pearson&#39;s Chi-squared test with Yates&#39; continuity correction #&gt; #&gt; data: titanic$Survived and titanic$Sex #&gt; X-squared = 484.02, df = 1, p-value &lt; 2.2e-16 Please recalculate the test statistic, i.e. the value: chisq.test(titanic$Survived, titanic$Sex)$statistic #&gt; X-squared #&gt; 484.0245 from the observed values. The formula for \\(X^2\\) is: addmargins(table(titanic$Survived, titanic$Sex)) \\(X^2 = \\sum_i \\frac{(O_i-E_i)^2}{E_i}\\), where \\(O_i\\) is the observed frequency and \\(E_i\\) is the expected frequency. The following steps are suggested. ## Step 1: Store the observed values in a table tab_obs &lt;- table(titanic$Survived, titanic$Sex) ## Step 2: Calculate expected absolute frequency library(&quot;DescTools&quot;) tab_exp &lt;- ExpFreq(XYZ, freq =&quot;abs&quot;) ## Step 3: Subtract the expected value from the observed value (and square differences) ## ... ## Step 4: Divide by expected values ## ... ## Step 5: Sum up all ## ... tab_margins &lt;- addmargins(table(titanic$Survived, titanic$Sex)) tab_obs &lt;- table(titanic$Survived, titanic$Sex) ## Step 1: Expected absolute frequency library(&quot;DescTools&quot;) tab_exp &lt;- ExpFreq(table(titanic$Survived, titanic$Sex), freq =&quot;abs&quot;) ## Step 2: Subtract the expected value from the observed value (and square differences) (tab_obs-tab_exp)^2 ## Step 3: Divide by expected values (tab_obs-tab_exp)^2/tab_exp ## Step 4: Sum up all tab_temp &lt;- (tab_obs-tab_exp)^2/tab_exp tab_temp[1,1] + tab_temp[1,2] + tab_temp[2,1] + tab_temp[2,2] 10.3 Addons 10.3.0.1 Some Are More Equal Than Others Let's extend the group analysis to multiple categories using the Pclass variable. The passenger class represents the socio-economic status of people. We hypothesize that people with more money used their influence to get into one of the lifeboats. First, the contingency table of the situation: tab &lt;- contingency_table(list(&quot;Passenger Class&quot;=&#39;Pclass&#39;), outcomes=list(&#39;Survival&#39;=&#39;Survived_fct&#39;), ## need to be factors crosstab_funcs=list(freq()), data=titanic_fct) neat_table(tab, format = c(&quot;html&quot;)) In first class, more people survived (n=168) than died (n=114) whereas this not true for the third class (365 died and 135 survived). All men may be created equal, but some are more equal than others. The logistic regression with one categorical variable is straightforward: logistic2 = glm(Survived ~ Pclass, family = binomial(link = &#39;logit&#39;), data = titanic) logistic2 #&gt; #&gt; Call: glm(formula = Survived ~ Pclass, family = binomial(link = &quot;logit&quot;), #&gt; data = titanic) #&gt; #&gt; Coefficients: #&gt; (Intercept) Pclass #&gt; 1.0860 -0.6921 #&gt; #&gt; Degrees of Freedom: 1042 Total (i.e. Null); 1041 Residual #&gt; Null Deviance: 1402 #&gt; Residual Deviance: 1320 AIC: 1324 The lower your socio-economic status, the less survival can you expect. 10.3.0.2 The Cheaper The Deader? We have another option to investigate the effect of socio-economic class, the Fare variable (ticket price). The prices of tickets on the Titanic in 1912 ranged from £870 or $4,350 for a first-class parlor suite to a maximum of £8 or $40 for a third-class passage, according to The Washington Times. A century later, in 2012, those ticket prices equaled a range of $50,000 to $460. logistic3 = glm(Survived ~ Fare, family = binomial(link = &#39;logit&#39;), data = titanic) logistic3 #&gt; #&gt; Call: glm(formula = Survived ~ Fare, family = binomial(link = &quot;logit&quot;), #&gt; data = titanic) #&gt; #&gt; Coefficients: #&gt; (Intercept) Fare #&gt; -0.80666 0.01109 #&gt; #&gt; Degrees of Freedom: 1042 Total (i.e. Null); 1041 Residual #&gt; Null Deviance: 1402 #&gt; Residual Deviance: 1337 AIC: 1341 The coefficient and intercept estimates give us the following equation: \\[ \\text{logit}(p) = -0.80666 + 0.01109 \\cdot \\text{fare} \\] In this case, the estimated coefficient for the intercept is the log odds of a passenger with a fare of zero surviving the accident. Of course, there is nothing like a free lunch. So the intercept in this model corresponds to the log odds of survival when fare is at the hypothetical value of zero. How do we interpret the slope coefficient for Fare? Let's fix Fare at some value, e.g. the mean which roughly equals 37 (rounded to 0 decimals). Then the conditional logit of surviving when the fare is equal to the mean is: \\[\\begin{aligned} \\text{logit}(p | \\text{fare}=36) &amp;= -0.3964565 \\\\ \\text{logit}(p | \\text{fare}=37) &amp;= -0.38537 \\\\ \\end{aligned}\\] We can examine the effect of a one-unit increase in fare by taking the difference of the two equations: \\[\\text{logit}(p | \\text{fare}=37) - \\text{logit}(p | \\text{fare}=36) = 0.0110866 \\] In other words, for a one-unit increase in the fare price, the expected change in log odds is 0.0110866. Can we translate this change in log odds to the change in odds? Indeed, we can. Recall that logarithm converts multiplication and division to addition and subtraction. Its inverse, the exponentiation converts addition and subtraction back to multiplication and division. If we exponentiate both sides of our last equation, we have the following: \\[ e^{\\text{logit}(p | \\text{fare}=37) - \\text{logit}(p | \\text{fare}=36)} = e^{0.0110866} = 1.011148 \\] So we can say for a one-unit increase in fare price, we expect to see about 1.1% increase in the odds of surviving. This 1.1% of increase does not depend on the value that fare is held at. Information about Britain’s currency at that time. Before Britain’s currency was in terms of pounds and pence, it was in terms of pounds, shillings and pennies e.g. £18 15s 9d. There were: 12 pennies per shilling and 20 shillings per pound. Can we get this information more directly? Yes, we can. require(MASS) exp(cbind(coef(logistic3), confint(logistic3))) #&gt; 2.5 % 97.5 % #&gt; (Intercept) 0.4463467 0.3780949 0.5250284 #&gt; Fare 1.0111482 1.0080791 1.0145089 10.3.0.3 The Bigger Picture First, we take another subset, since PassengerId, Name and Ticket are not good predictors. logistic4 = glm(Survived ~ ., family = binomial(link = &#39;logit&#39;), data = titanic[,-c(1,3,8)]) logistic4 #&gt; #&gt; Call: glm(formula = Survived ~ ., family = binomial(link = &quot;logit&quot;), #&gt; data = titanic[, -c(1, 3, 8)]) #&gt; #&gt; Coefficients: #&gt; (Intercept) Pclass Sexmale Age SibSp Parch #&gt; 5.352939 -1.024737 -3.685172 -0.035433 -0.314696 -0.117345 #&gt; Fare EmbarkedQ EmbarkedS #&gt; 0.001863 -0.283354 -0.201081 #&gt; #&gt; Degrees of Freedom: 1042 Total (i.e. Null); 1034 Residual #&gt; Null Deviance: 1402 #&gt; Residual Deviance: 784.2 AIC: 802.2 For example, increase one unit in age will decrease the log odd of survival by 0.0257; being a male will decrease the log odd of survival by 3.78 compared to female; and being in class2 will decrease the log odd of survival by 1.17, being in class3 will decrease the log odd of survival by 1.97. Moreover, exponentiate the model coefficients can look at the result and interpret its meaning at a different angle. Below are table of the “odd ratio” value for each predictor coefficient relative to the survival and their respective 95% confident interval odd ratio value. exp(cbind(OR = coef(logistic4))) #&gt; OR #&gt; (Intercept) 211.22820034 #&gt; Pclass 0.35889085 #&gt; Sexmale 0.02509285 #&gt; Age 0.96518770 #&gt; SibSp 0.73001047 #&gt; Parch 0.88927819 #&gt; Fare 1.00186428 #&gt; EmbarkedQ 0.75325288 #&gt; EmbarkedS 0.81784593 Now, the result can be interpreted as: for a unit increase in age, the odds of surviving from the incident decrease by a factor of 0.96; and being a third class (class3), the odds of surviving decrease by a factor of 0.12, etc. The logit model coefficients can be presented as odds ratios. But odds-ratios are often misinterpreted as if they were relative risks/probabilities. Nonetheless presenting odds-ratios is standard practice in the medical literature. 10.3.0.4 Marginal Effects Marginal effects is a way of presenting results as differences in probabilities, which is more informative than odds-ratios and relative risk. For continuous variables this represents the instantaneous change given that the ‘unit’ may be very small. For binary variables, the change is from 0 to 1, so one ‘unit’ as it is usually thought. In order to express the more intuitive change in the predicted probability that the outcome equals 1 requires conditioning on all other included variables (i.e., selecting a set of values for all righthand-side variables) and running that set of values through the link function to convert log-odds to probabilities, thus making the marginal effect (in probability terms) of one variable a function of all other variables included in the model. Marginal effects show the change in probability when the predictor or independent variable increases by one unit. library(margins) summary(margins(logistic4)) #&gt; factor AME SE z p lower upper #&gt; Age -0.0041 0.0008 -4.9223 0.0000 -0.0057 -0.0024 #&gt; EmbarkedQ -0.0326 0.0561 -0.5816 0.5608 -0.1425 0.0773 #&gt; EmbarkedS -0.0233 0.0283 -0.8233 0.4103 -0.0787 0.0321 #&gt; Fare 0.0002 0.0002 0.8831 0.3772 -0.0003 0.0007 #&gt; Parch -0.0134 0.0130 -1.0356 0.3004 -0.0389 0.0120 #&gt; Pclass -0.1173 0.0167 -7.0181 0.0000 -0.1501 -0.0846 #&gt; Sexmale -0.6601 0.0253 -26.0454 0.0000 -0.7098 -0.6105 #&gt; SibSp -0.0360 0.0134 -2.6865 0.0072 -0.0623 -0.0097 "],["interaction-models.html", "Chapter 11 Interaction Models 11.1 Motivation 11.2 Load and Merge 11.3 Data Manipulation 11.4 Simple linear model 11.5 Multiple regression with control 11.6 Multiple regression with moderator 11.7 Marginal Effects", " Chapter 11 Interaction Models 11.1 Motivation A sports doctor routinely measures the muscle percentages of his clients. He also asks them how many hours per week they typically spend on training. Our doctor suspects that clients who train more are also more muscled. Furthermore, he thinks that the effect of training on muscularity declines with age. In multiple regression analysis, this is known as a moderation or interaction effect. The figure below illustrates it. Imagine a 35 year old student and a 49 year old professor who work out at McFit (Lenne Passage). They exercise exactly the same amount of time per week (3 day split), the same exercises (McFit usually provides multiple identical machines next to each other), the same time of the day, they take the nutritional supplements, etc. etc. everything else is constant. Do you think they will experience different results in terms of muscle gains? In mathematical terms the interaction is a multiplication: \\[ muscle = training + age + training*age \\] 11.2 Load and Merge We analyze the details of the weight-height relationship. library(haven) pequiv &lt;- read_dta(&quot;./SOEPteaching/pequiv.dta&quot;, col_select = c(&quot;pid&quot;, &quot;syear&quot;, &quot;d11101&quot;, &quot;d11102ll&quot;, &quot;l11102&quot;, &quot;d11104&quot;)) health &lt;- read_dta(&quot;./SOEPteaching/health.dta&quot;, col_select = c(&quot;pid&quot;, &quot;syear&quot;, &quot;height&quot;, &quot;weight&quot;)) master &lt;- merge(pequiv, health, by = c(&quot;pid&quot;, &quot;syear&quot;)) 11.3 Data Manipulation Drop Stata labels, rename the variables, and create factor variables. library(sjlabelled) soep &lt;- remove_all_labels(master) library(tidyverse) soep &lt;- soep %&gt;% rename(region = l11102, marital = d11104, age = d11101, gender = d11102ll) %&gt;% filter(height &gt; 0, weight &gt; 0, marital &gt; 0) %&gt;% mutate(marital = factor(marital, levels = c(1, 2, 3, 4, 5)), region = factor(region, levels = c(1, 2)), gender = factor(gender, levels = c(1, 2))) levels(soep$marital) = c(&quot;married&quot;, &quot;single&quot;, &quot;widowed&quot;, &quot;divorced&quot;, &quot;separated&quot;) levels(soep$region) = c(&quot;west&quot;, &quot;east&quot;) levels(soep$gender) = c(&quot;male&quot;, &quot;female&quot;) Inspect the data (check for missings and outliers): library(gtsummary) tbl_summary(soep[-c(1,2)]) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #wmbjdrtjbq .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #wmbjdrtjbq .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #wmbjdrtjbq .gt_caption { padding-top: 4px; padding-bottom: 4px; } #wmbjdrtjbq .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #wmbjdrtjbq .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #wmbjdrtjbq .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #wmbjdrtjbq .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #wmbjdrtjbq .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #wmbjdrtjbq .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #wmbjdrtjbq .gt_column_spanner_outer:first-child { padding-left: 0; } #wmbjdrtjbq .gt_column_spanner_outer:last-child { padding-right: 0; } #wmbjdrtjbq .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #wmbjdrtjbq .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #wmbjdrtjbq .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #wmbjdrtjbq .gt_from_md > :first-child { margin-top: 0; } #wmbjdrtjbq .gt_from_md > :last-child { margin-bottom: 0; } #wmbjdrtjbq .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #wmbjdrtjbq .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #wmbjdrtjbq .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #wmbjdrtjbq .gt_row_group_first td { border-top-width: 2px; } #wmbjdrtjbq .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #wmbjdrtjbq .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #wmbjdrtjbq .gt_first_summary_row.thick { border-top-width: 2px; } #wmbjdrtjbq .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #wmbjdrtjbq .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #wmbjdrtjbq .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #wmbjdrtjbq .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #wmbjdrtjbq .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #wmbjdrtjbq .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #wmbjdrtjbq .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #wmbjdrtjbq .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #wmbjdrtjbq .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #wmbjdrtjbq .gt_left { text-align: left; } #wmbjdrtjbq .gt_center { text-align: center; } #wmbjdrtjbq .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #wmbjdrtjbq .gt_font_normal { font-weight: normal; } #wmbjdrtjbq .gt_font_bold { font-weight: bold; } #wmbjdrtjbq .gt_font_italic { font-style: italic; } #wmbjdrtjbq .gt_super { font-size: 65%; } #wmbjdrtjbq .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #wmbjdrtjbq .gt_asterisk { font-size: 100%; vertical-align: 0; } #wmbjdrtjbq .gt_indent_1 { text-indent: 5px; } #wmbjdrtjbq .gt_indent_2 { text-indent: 10px; } #wmbjdrtjbq .gt_indent_3 { text-indent: 15px; } #wmbjdrtjbq .gt_indent_4 { text-indent: 20px; } #wmbjdrtjbq .gt_indent_5 { text-indent: 25px; } Characteristic N = 103,9501 gender     male 49,646 (48%)     female 54,304 (52%) age 47 (35, 62) marital     married 61,332 (59%)     single 25,921 (25%)     widowed 6,205 (6.0%)     divorced 8,010 (7.7%)     separated 2,482 (2.4%) region     west 80,387 (77%)     east 23,563 (23%) height 171 (165, 178) weight 75 (65, 86) 1 n (%); Median (IQR) 11.4 Simple linear model You learned that simple regression is almost identical to correlation between two variables. simple &lt;- lm(weight ~ height, data=soep) simple #&gt; #&gt; Call: #&gt; lm(formula = weight ~ height, data = soep) #&gt; #&gt; Coefficients: #&gt; (Intercept) height #&gt; -78.4362 0.9034 11.5 Multiple regression with control 11.5.1 Regression model Here comes multiple regression. We have seen this before: multiple &lt;- lm(weight ~ height + gender, data=soep) multiple #&gt; #&gt; Call: #&gt; lm(formula = weight ~ height + gender, data = soep) #&gt; #&gt; Coefficients: #&gt; (Intercept) height genderfemale #&gt; -37.567 0.684 -6.188 11.5.2 Visualization (parallel slopes) We have seen parallel slopes before: Conclusion: The fundamental truth is that the effect of body height on body weight is identical across gender (i.e. for males and females). Males and female are equipped (by nature) with a different starting body weight on average. 11.6 Multiple regression with moderator 11.6.1 Interaction (dummy * dummy) interact0a &lt;- lm(weight ~ region*gender, data=soep) summary(interact0a) #&gt; #&gt; Call: #&gt; lm(formula = weight ~ region * gender, data = soep) #&gt; #&gt; Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -54.401 -9.987 -2.183 7.599 165.599 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) 84.40098 0.07542 1119.145 &lt; 2e-16 *** #&gt; regioneast -0.41388 0.15848 -2.612 0.00901 ** #&gt; genderfemale -15.21763 0.10435 -145.826 &lt; 2e-16 *** #&gt; regioneast:genderfemale 1.50228 0.21919 6.854 7.24e-12 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Residual standard error: 14.78 on 103946 degrees of freedom #&gt; Multiple R-squared: 0.2022, Adjusted R-squared: 0.2021 #&gt; F-statistic: 8780 on 3 and 103946 DF, p-value: &lt; 2.2e-16 First glimpse at the margins package. library(margins) #margins(interact0a) summary(margins(interact0a, at = list(region = c(&quot;west&quot;, &quot;east&quot;)))) #&gt; factor region AME SE z p lower upper #&gt; genderfemale 1.0000 -15.2176 0.1044 -145.8260 0.0000 -15.4222 -15.0131 #&gt; genderfemale 2.0000 -13.7153 0.1928 -71.1532 0.0000 -14.0931 -13.3376 #&gt; regioneast 1.0000 0.3709 0.1095 3.3879 0.0007 0.1563 0.5855 #&gt; regioneast 2.0000 0.3709 0.1095 3.3879 0.0007 0.1563 0.5855 Interaction plot from the interactions package. # Dedicated package makes everything easier. library(interactions) cat_plot(interact0a, pred = gender, modx = region) 11.6.2 Interaction (categorical * dummy) interact0b &lt;- lm(weight ~ marital*gender, data=soep) interact0b #&gt; #&gt; Call: #&gt; lm(formula = weight ~ marital * gender, data = soep) #&gt; #&gt; Coefficients: #&gt; (Intercept) maritalsingle #&gt; 85.92239 -5.38961 #&gt; maritalwidowed maritaldivorced #&gt; -4.34815 -0.08313 #&gt; maritalseparated genderfemale #&gt; -1.25931 -15.50285 #&gt; maritalsingle:genderfemale maritalwidowed:genderfemale #&gt; 0.77077 4.85503 #&gt; maritaldivorced:genderfemale maritalseparated:genderfemale #&gt; 0.44475 1.13259 11.6.3 Interaction (continuous * dummy) Note that R automatically adds main effects if you use multiplication operator: Thus \\[ height * female \\] translates to \\[ height + female + height*female \\] interact1 &lt;- lm(weight ~ height*gender, data=soep) interact1 #&gt; #&gt; Call: #&gt; lm(formula = weight ~ height * gender, data = soep) #&gt; #&gt; Coefficients: #&gt; (Intercept) height genderfemale #&gt; -58.7988 0.8031 37.5708 #&gt; height:genderfemale #&gt; -0.2553 11.6.4 Visualization (non-parallel slopes) library(interactions) interact_plot(interact1, pred = height, modx = gender, main.title = &quot;Each group has a different slope.&quot;) Conclusion: The fundamental truth is that the effect of body height on body weight is similar but not identical between males and females. A boy and and girl of exact same body height who experience growth by 1cm are expected to end up with different weight gains. There is effect heterogeneity. 11.6.5 Interaction (continuous * continuous) interact2 &lt;- lm(weight ~ height*age, data=soep) interact2 #&gt; #&gt; Call: #&gt; lm(formula = weight ~ height * age, data = soep) #&gt; #&gt; Coefficients: #&gt; (Intercept) height age height:age #&gt; -80.661777 0.861444 -0.213555 0.002397 The interaction of two continuous variables is harder to interpret. We cannot set the moderator (age) equal to zero, since there is no person with an age of zero (in SOEP). 11.6.6 Visualization (non-parallel slopes) There are conventions to help you choose the best values of the continuous moderator for plotting predicted values. But these conventions don't always work in every situation. For example, one convention suggested by Cohen and Cohen and popularized by Aiken and West is to use three values of the moderator: the mean, the value one standard deviation above, and the value one standard deviation below the mean. This is what interact_plot() does by default. interact_plot(interact2, pred = height, modx = age) This shows you that interaction between two continuous variables works basically the same way as for a categorical and continuous variable. An interaction says that there's not a fixed offset: you need to consider both values of x1 and x2 simultaneously in order to predict y. You can see that even with just two continuous variables, coming up with good visualizations are hard. But that's reasonable: you shouldn't expect it will be easy to understand how three or more variables simultaneously interact! But again, we're saved a little because we're using models for exploration, and you can gradually build up your model over time. The model doesn't have to be perfect, it just has to help you reveal a little more about your data. Conclusion: The fundamental truth is that the effect of body height on body weight is identical across age. In the regression output age has non-significant coefficients. The interaction plot is suggesting that there is no effect heterogeneity with respect to age (multiple parallel slopes). 11.7 Marginal Effects Now we better understand that the effect of our main explanatory variable might be increased or decreased by another variable. Still, a question is open to answer: What exactly is the effect of our main explanatory variable in the interaction model? In OLS framework regression coefficients have direct interpretation as unconditional marginal effects: predicted change in y due to a unit change in x. Interactions or higher-order terms (e.g. age square) make interpretation difficult or impossible. For interpretation of the effect and the statistical significance, we have to investigate all interacted variables at the same time. Marginal effects are partial derivatives of the regression equation with respect to a variable from the model. \\[ \\begin{align} weight &amp;= \\beta_0 + \\beta_1 \\cdot height \\tag{simple regression} \\\\ \\frac{\\partial weight}{\\partial height} &amp;= \\beta_1 \\tag{unconditional effect} \\\\ weight &amp;= \\beta_0 + \\beta_1 \\cdot height + \\beta_2 \\cdot female + \\beta_3 \\cdot height \\cdot female \\tag{moderated regression} \\\\ \\frac{\\partial weight}{\\partial height} &amp;= \\beta_1 + \\beta_3 \\cdot female \\tag{conditional effect} \\\\ \\end{align} \\] library(stargazer) stargazer(simple, interact1, type=&quot;text&quot;) #&gt; #&gt; ================================================================================= #&gt; Dependent variable: #&gt; ------------------------------------------------------------- #&gt; weight #&gt; (1) (2) #&gt; --------------------------------------------------------------------------------- #&gt; height 0.903*** 0.803*** #&gt; (0.005) (0.008) #&gt; #&gt; genderfemale 37.571*** #&gt; (2.125) #&gt; #&gt; height:genderfemale -0.255*** #&gt; (0.012) #&gt; #&gt; Constant -78.436*** -58.799*** #&gt; (0.799) (1.508) #&gt; #&gt; --------------------------------------------------------------------------------- #&gt; Observations 103,950 103,950 #&gt; R2 0.267 0.289 #&gt; Adjusted R2 0.266 0.289 #&gt; Residual Std. Error 14.170 (df = 103948) 13.955 (df = 103946) #&gt; F Statistic 37,767.980*** (df = 1; 103948) 14,056.330*** (df = 3; 103946) #&gt; ================================================================================= #&gt; Note: *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01 For the simple regression, the coefficient is identical (unconditional). library(margins) margins(simple) #&gt; height #&gt; 0.9034 11.7.1 Marginal effects at representatives (TASK) We can use representative values which we literally plug in the equation. These are the effects for each group (what we have seen before in the interaction plot): \\[ \\begin{align} weight &amp;= \\beta_0 + \\beta_1 \\cdot height + \\beta_2 \\cdot female + \\beta_3 \\cdot height \\cdot female \\tag{interact1} \\\\ \\frac{\\partial weight}{\\partial height} &amp;= \\beta_1 + \\beta_3 \\cdot female \\tag{conditional effect} \\\\ \\end{align} \\] Here is the R code: margins(interact1, at = list(gender = c(&quot;male&quot;, &quot;female&quot;))) #&gt; at(gender) height genderfemale #&gt; male 0.8031 -6.224 #&gt; female 0.5479 -6.224 Please calculate the MER of height in interact1 for the two gender programmtic in R. 11.7.2 Marginal effects at the mean (TASK) Plugging in values is not always as easy as it seems to be. What should we use for age? Values as 0, 1 or 2 does not makes sense for age. Okay, we could use some representative age, e.g. 30 and 40. But what is our theoretical justification to report the effect for age 30 and not age 31? Another strategy is to use mean values of the variables. \\[ \\begin{align} weight &amp;= \\beta_0 + \\beta_1 \\cdot height + \\beta_2 \\cdot age + \\beta_3 \\cdot height \\cdot age \\tag{interact2} \\\\ \\frac{\\partial weight}{\\partial height} &amp;= \\beta_1 + \\beta_3 \\cdot age \\tag{conditional effect} \\\\ \\end{align} \\] library(&quot;stargazer&quot;) stargazer(simple, interact2, type=&quot;text&quot;) #&gt; #&gt; ================================================================================= #&gt; Dependent variable: #&gt; ------------------------------------------------------------- #&gt; weight #&gt; (1) (2) #&gt; --------------------------------------------------------------------------------- #&gt; height 0.903*** 0.861*** #&gt; (0.005) (0.013) #&gt; #&gt; age -0.214*** #&gt; (0.044) #&gt; #&gt; height:age 0.002*** #&gt; (0.0003) #&gt; #&gt; Constant -78.436*** -80.662*** #&gt; (0.799) (2.214) #&gt; #&gt; --------------------------------------------------------------------------------- #&gt; Observations 103,950 103,950 #&gt; R2 0.267 0.309 #&gt; Adjusted R2 0.266 0.309 #&gt; Residual Std. Error 14.170 (df = 103948) 13.751 (df = 103946) #&gt; F Statistic 37,767.980*** (df = 1; 103948) 15,516.970*** (df = 3; 103946) #&gt; ================================================================================= #&gt; Note: *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01 Here is the R code with margins: interact2 &lt;- lm(weight ~ height*age, data=soep) interact2 #&gt; #&gt; Call: #&gt; lm(formula = weight ~ height * age, data = soep) #&gt; #&gt; Coefficients: #&gt; (Intercept) height age height:age #&gt; -80.661777 0.861444 -0.213555 0.002397 #summary(margins(interact2)) margins(interact2, at = list(age = mean_age)) #&gt; at(age) height age #&gt; 48.05 0.9766 0.1977 Please calculate the MEM of height in interact2 programmtic in R. 11.7.3 Average marginal effects The default margins commands shows you something else than MER and MEM, namely average marginal effects. AMEs calculate marginal effects at every observed value of X and average across the resulting effect estimates. AMEs are particularly useful because -- unlike MEMs -- produce a single quantity summary that reflects the full distribution of X rather than an arbitrary prediction. margins(interact1) #&gt; height genderfemale #&gt; 0.6698 -6.224 A summary provides you with information that cannot easily be calculated by hand, e.g. standard error, p-value, confidence interval: summary(margins(interact1)) #&gt; factor AME SE z p lower upper #&gt; genderfemale -6.2236 0.1169 -53.2405 0.0000 -6.4527 -5.9945 #&gt; height 0.6698 0.0062 107.8003 0.0000 0.6576 0.6820 "],["fixed-effects.html", "Chapter 12 Fixed effects 12.1 Cross-sectional Data (2 pt) 12.2 Panel Data (2 pt) 12.3 Fixed Effects Regression", " Chapter 12 Fixed effects 12.1 Cross-sectional Data (2 pt) Suppose you want to learn the effect of price on the demand for back massages. Read in the following data from four Midwest locations (call it crosssection) and print the table with the gt package. # Crosssection crosssection &lt;- data.frame(Location = c(&quot;Chicago&quot;, &quot;Peoria&quot;, &quot;Milwaukee&quot;, &quot;Madison&quot;), Year = rep(2003, 4), Price = c(75, 50, 60, 55), Quantity = c(2.0, 1.0, 1.5, 0.8)) library(ggplot2) library(gt) table_1 &lt;- gt(data = crosssection) %&gt;% tab_header(title = &quot;Table 1: Cross-sectional Data&quot;) %&gt;% cols_label( Location = md(&quot;**Location**&quot;), Year = md(&quot;**Year**&quot;), Price = md(&quot;**Price**&quot;), Quantity = md(&quot;**Per Capita&lt;br&gt;Quantity**&quot;) ) # Show the gt Table table_1 html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #dvjxsmnimw .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #dvjxsmnimw .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #dvjxsmnimw .gt_caption { padding-top: 4px; padding-bottom: 4px; } #dvjxsmnimw .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #dvjxsmnimw .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #dvjxsmnimw .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #dvjxsmnimw .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #dvjxsmnimw .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #dvjxsmnimw .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #dvjxsmnimw .gt_column_spanner_outer:first-child { padding-left: 0; } #dvjxsmnimw .gt_column_spanner_outer:last-child { padding-right: 0; } #dvjxsmnimw .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #dvjxsmnimw .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #dvjxsmnimw .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #dvjxsmnimw .gt_from_md > :first-child { margin-top: 0; } #dvjxsmnimw .gt_from_md > :last-child { margin-bottom: 0; } #dvjxsmnimw .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #dvjxsmnimw .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #dvjxsmnimw .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #dvjxsmnimw .gt_row_group_first td { border-top-width: 2px; } #dvjxsmnimw .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #dvjxsmnimw .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #dvjxsmnimw .gt_first_summary_row.thick { border-top-width: 2px; } #dvjxsmnimw .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #dvjxsmnimw .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #dvjxsmnimw .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #dvjxsmnimw .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #dvjxsmnimw .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #dvjxsmnimw .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #dvjxsmnimw .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #dvjxsmnimw .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #dvjxsmnimw .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #dvjxsmnimw .gt_left { text-align: left; } #dvjxsmnimw .gt_center { text-align: center; } #dvjxsmnimw .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #dvjxsmnimw .gt_font_normal { font-weight: normal; } #dvjxsmnimw .gt_font_bold { font-weight: bold; } #dvjxsmnimw .gt_font_italic { font-style: italic; } #dvjxsmnimw .gt_super { font-size: 65%; } #dvjxsmnimw .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #dvjxsmnimw .gt_asterisk { font-size: 100%; vertical-align: 0; } #dvjxsmnimw .gt_indent_1 { text-indent: 5px; } #dvjxsmnimw .gt_indent_2 { text-indent: 10px; } #dvjxsmnimw .gt_indent_3 { text-indent: 15px; } #dvjxsmnimw .gt_indent_4 { text-indent: 20px; } #dvjxsmnimw .gt_indent_5 { text-indent: 25px; } Table 1: Cross-sectional Data Location Year Price Per CapitaQuantity Chicago 2003 75 2.0 Peoria 2003 50 1.0 Milwaukee 2003 60 1.5 Madison 2003 55 0.8 Please create the plot (in Base R or ggplot). 12.2 Panel Data (2 pt) Read in additional data from Table 2 (call it paneldata). library(ggplot2) library(tidyverse) # Panel Data paneldata &lt;- data.frame(Location = c(&quot;Chicago&quot;, &quot;Chicago&quot;, &quot;Peoria&quot;, &quot;Peoria&quot;, &quot;Milwaukee&quot;, &quot;Milwaukee&quot;, &quot;Madison&quot;, &quot;Madison&quot;), Year = rep(2003:2004, 4), Price = c(75, 85, 50, 48, 60, 65, 55, 60), Quantity = c(2.0, 1.8, 1.0, 1.1, 1.5, 1.4, 0.8, 0.7)) table_2 &lt;- gt(data = paneldata) %&gt;% tab_header(title = &quot;Table 2: Panel Data&quot;) %&gt;% cols_label( Location = md(&quot;**Location**&quot;), Year = md(&quot;**Year**&quot;), Price = md(&quot;**Price**&quot;), Quantity = md(&quot;**Per Capita&lt;br&gt;Quantity**&quot;) ) table_2 html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #oszjmafuvc .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #oszjmafuvc .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #oszjmafuvc .gt_caption { padding-top: 4px; padding-bottom: 4px; } #oszjmafuvc .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #oszjmafuvc .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #oszjmafuvc .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #oszjmafuvc .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #oszjmafuvc .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #oszjmafuvc .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #oszjmafuvc .gt_column_spanner_outer:first-child { padding-left: 0; } #oszjmafuvc .gt_column_spanner_outer:last-child { padding-right: 0; } #oszjmafuvc .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #oszjmafuvc .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #oszjmafuvc .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #oszjmafuvc .gt_from_md > :first-child { margin-top: 0; } #oszjmafuvc .gt_from_md > :last-child { margin-bottom: 0; } #oszjmafuvc .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #oszjmafuvc .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #oszjmafuvc .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #oszjmafuvc .gt_row_group_first td { border-top-width: 2px; } #oszjmafuvc .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #oszjmafuvc .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #oszjmafuvc .gt_first_summary_row.thick { border-top-width: 2px; } #oszjmafuvc .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #oszjmafuvc .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #oszjmafuvc .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #oszjmafuvc .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #oszjmafuvc .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #oszjmafuvc .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #oszjmafuvc .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #oszjmafuvc .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #oszjmafuvc .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #oszjmafuvc .gt_left { text-align: left; } #oszjmafuvc .gt_center { text-align: center; } #oszjmafuvc .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #oszjmafuvc .gt_font_normal { font-weight: normal; } #oszjmafuvc .gt_font_bold { font-weight: bold; } #oszjmafuvc .gt_font_italic { font-style: italic; } #oszjmafuvc .gt_super { font-size: 65%; } #oszjmafuvc .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #oszjmafuvc .gt_asterisk { font-size: 100%; vertical-align: 0; } #oszjmafuvc .gt_indent_1 { text-indent: 5px; } #oszjmafuvc .gt_indent_2 { text-indent: 10px; } #oszjmafuvc .gt_indent_3 { text-indent: 15px; } #oszjmafuvc .gt_indent_4 { text-indent: 20px; } #oszjmafuvc .gt_indent_5 { text-indent: 25px; } Table 2: Panel Data Location Year Price Per CapitaQuantity Chicago 2003 75 2.0 Chicago 2004 85 1.8 Peoria 2003 50 1.0 Peoria 2004 48 1.1 Milwaukee 2003 60 1.5 Milwaukee 2004 65 1.4 Madison 2003 55 0.8 Madison 2004 60 0.7 Please create the plot. ggplot(paneldata, aes(x=Price, y=Quantity)) + geom_point() + labs(title=&quot;Relationship between Price and Quantity&quot;, x=&quot;Price&quot;, y=&quot;Quantity&quot;) + geom_smooth(aes(colour = Location), method = &quot;lm&quot;, se = FALSE) + geom_smooth(method = &quot;lm&quot;, se = FALSE) 12.3 Fixed Effects Regression 12.3.1 First Difference (2 pt) Please add two columns, i.e. the change in price (name it P_diff) and the change in quantity (name it Q_diff) to your dataframe (1 pt). table3 &lt;- paneldata %&gt;% group_by(Location) %&gt;% mutate(P_diff = Price - lag(Price), Q_diff = Quantity - lag(Quantity)) #library(xtable) # may handle formulas in colnames #print(xtable(table3)), type = &quot;html&quot;) #print(xtable(head(cars)), type = &quot;html&quot;) #print(xtable(table3), type = &quot;html&quot;) library(gt) gt(data = table3, rowname_col = TRUE, groupname_col=FALSE) %&gt;% tab_header(title = &quot;Table 3: Data for Difference Equation Estimation.&quot;) %&gt;% cols_label( Location = md(&quot;**Location**&quot;), Year = md(&quot;**Year**&quot;), Price = md(&quot;**Price**&quot;), Quantity = md(&quot;**Per Capita&lt;br&gt;Quantity**&quot;), P_diff = md(&quot;**Delta P**&quot;), Q_diff = md(&quot;**Delta Q**&quot;)) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #osaqrooudn .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #osaqrooudn .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #osaqrooudn .gt_caption { padding-top: 4px; padding-bottom: 4px; } #osaqrooudn .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #osaqrooudn .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #osaqrooudn .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #osaqrooudn .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #osaqrooudn .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #osaqrooudn .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #osaqrooudn .gt_column_spanner_outer:first-child { padding-left: 0; } #osaqrooudn .gt_column_spanner_outer:last-child { padding-right: 0; } #osaqrooudn .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #osaqrooudn .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #osaqrooudn .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #osaqrooudn .gt_from_md > :first-child { margin-top: 0; } #osaqrooudn .gt_from_md > :last-child { margin-bottom: 0; } #osaqrooudn .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #osaqrooudn .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #osaqrooudn .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #osaqrooudn .gt_row_group_first td { border-top-width: 2px; } #osaqrooudn .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #osaqrooudn .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #osaqrooudn .gt_first_summary_row.thick { border-top-width: 2px; } #osaqrooudn .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #osaqrooudn .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #osaqrooudn .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #osaqrooudn .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #osaqrooudn .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #osaqrooudn .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #osaqrooudn .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #osaqrooudn .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #osaqrooudn .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #osaqrooudn .gt_left { text-align: left; } #osaqrooudn .gt_center { text-align: center; } #osaqrooudn .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #osaqrooudn .gt_font_normal { font-weight: normal; } #osaqrooudn .gt_font_bold { font-weight: bold; } #osaqrooudn .gt_font_italic { font-style: italic; } #osaqrooudn .gt_super { font-size: 65%; } #osaqrooudn .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #osaqrooudn .gt_asterisk { font-size: 100%; vertical-align: 0; } #osaqrooudn .gt_indent_1 { text-indent: 5px; } #osaqrooudn .gt_indent_2 { text-indent: 10px; } #osaqrooudn .gt_indent_3 { text-indent: 15px; } #osaqrooudn .gt_indent_4 { text-indent: 20px; } #osaqrooudn .gt_indent_5 { text-indent: 25px; } Table 3: Data for Difference Equation Estimation. Location Year Price Per CapitaQuantity Delta P Delta Q Chicago 2003 75 2.0 NA NA Chicago 2004 85 1.8 10 -0.2 Peoria 2003 50 1.0 NA NA Peoria 2004 48 1.1 -2 0.1 Milwaukee 2003 60 1.5 NA NA Milwaukee 2004 65 1.4 5 -0.1 Madison 2003 55 0.8 NA NA Madison 2004 60 0.7 5 -0.1 Run a first difference estimation by regressing change in quantity on change in price (1 pt). 12.3.2 Within Estimator (2 pt) Run a within fixed effects regression in two ways. Function plm() from plm package. Replicate time demeaning programmatic in R. Calculate the mean of Q and P per individual (group). Subtract the individual mean from each observation. Regress these time-demeaned observation (with standard lm command). table4 &lt;- paneldata %&gt;% group_by(Location) %&gt;% mutate(P_diff = Price - lag(Price), Q_diff = Quantity - lag(Quantity), P_P_mean = Price - mean(Price), Q_Q_mean = Quantity - mean(Quantity)) library(gt) gt(data = table4, rowname_col = TRUE, groupname_col=FALSE) %&gt;% tab_header(title = &quot;Table 4: Data for Within Time Demean Estimation.&quot;) %&gt;% cols_label( Location = md(&quot;**Location**&quot;), Year = md(&quot;**Year**&quot;), Price = md(&quot;**Price**&quot;), Quantity = md(&quot;**Per Capita&lt;br&gt;Quantity**&quot;), P_diff = md(&quot;**Delta P**&quot;), Q_diff = md(&quot;**Delta Q**&quot;), P_P_mean = md(&quot;**P - mean(P)**&quot;), Q_Q_mean = md(&quot;**Q - mean(Q)**&quot;)) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #nqjpwvjqnf .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #nqjpwvjqnf .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #nqjpwvjqnf .gt_caption { padding-top: 4px; padding-bottom: 4px; } #nqjpwvjqnf .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #nqjpwvjqnf .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #nqjpwvjqnf .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #nqjpwvjqnf .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #nqjpwvjqnf .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #nqjpwvjqnf .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #nqjpwvjqnf .gt_column_spanner_outer:first-child { padding-left: 0; } #nqjpwvjqnf .gt_column_spanner_outer:last-child { padding-right: 0; } #nqjpwvjqnf .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #nqjpwvjqnf .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #nqjpwvjqnf .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #nqjpwvjqnf .gt_from_md > :first-child { margin-top: 0; } #nqjpwvjqnf .gt_from_md > :last-child { margin-bottom: 0; } #nqjpwvjqnf .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #nqjpwvjqnf .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #nqjpwvjqnf .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #nqjpwvjqnf .gt_row_group_first td { border-top-width: 2px; } #nqjpwvjqnf .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #nqjpwvjqnf .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #nqjpwvjqnf .gt_first_summary_row.thick { border-top-width: 2px; } #nqjpwvjqnf .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #nqjpwvjqnf .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #nqjpwvjqnf .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #nqjpwvjqnf .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #nqjpwvjqnf .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #nqjpwvjqnf .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #nqjpwvjqnf .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #nqjpwvjqnf .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #nqjpwvjqnf .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #nqjpwvjqnf .gt_left { text-align: left; } #nqjpwvjqnf .gt_center { text-align: center; } #nqjpwvjqnf .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #nqjpwvjqnf .gt_font_normal { font-weight: normal; } #nqjpwvjqnf .gt_font_bold { font-weight: bold; } #nqjpwvjqnf .gt_font_italic { font-style: italic; } #nqjpwvjqnf .gt_super { font-size: 65%; } #nqjpwvjqnf .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #nqjpwvjqnf .gt_asterisk { font-size: 100%; vertical-align: 0; } #nqjpwvjqnf .gt_indent_1 { text-indent: 5px; } #nqjpwvjqnf .gt_indent_2 { text-indent: 10px; } #nqjpwvjqnf .gt_indent_3 { text-indent: 15px; } #nqjpwvjqnf .gt_indent_4 { text-indent: 20px; } #nqjpwvjqnf .gt_indent_5 { text-indent: 25px; } Table 4: Data for Within Time Demean Estimation. Location Year Price Per CapitaQuantity Delta P Delta Q P - mean(P) Q - mean(Q) Chicago 2003 75 2.0 NA NA -5.0 0.10 Chicago 2004 85 1.8 10 -0.2 5.0 -0.10 Peoria 2003 50 1.0 NA NA 1.0 -0.05 Peoria 2004 48 1.1 -2 0.1 -1.0 0.05 Milwaukee 2003 60 1.5 NA NA -2.5 0.05 Milwaukee 2004 65 1.4 5 -0.1 2.5 -0.05 Madison 2003 55 0.8 NA NA -2.5 0.05 Madison 2004 60 0.7 5 -0.1 2.5 -0.05 12.3.3 LSDV (1 pt) Run a LSDV regression, i.e. include all individuals as dummy variables in your standard lm regression. 12.3.4 Comparison (1 pt) Create a model overview with stargazer. Start with a pooling model. You should have 5 models in total. You need to play around with stargazer options in order to make it good looking. Drop the constant in all your models. Drop model.numbers and dep.var.labels.include or the F statistic. You can relabel column.labels in stargazer as well. Your result should look like this: paneldata &lt;- data.frame(Location = c(&quot;Chicago&quot;, &quot;Chicago&quot;, &quot;Peoria&quot;, &quot;Peoria&quot;, &quot;Milwaukee&quot;, &quot;Milwaukee&quot;, &quot;Madison&quot;, &quot;Madison&quot;), Year = rep(2003:2004, 4), Price = c(75, 85, 50, 48, 60, 65, 55, 60), Quantity = c(2.0, 1.8, 1.0, 1.1, 1.5, 1.4, 0.8, 0.7)) library(sjmisc) library(tidyverse) paneldata &lt;- paneldata %&gt;% group_by(Location) %&gt;% mutate(dP = last(Price) - first(Price), dQ = last(Quantity) - first(Quantity), dP=replace(dP, row_number()==1, NA), dQ=replace(dQ, row_number()==1, NA), mean_P = mean(Price), mean_Q = mean(Quantity), P_mean_P = Price - mean_P, Q_mean_Q = Quantity - mean_Q, Price_ave = Price - ave(Price, Location), Quantity_ave = Quantity - ave(Quantity, Location)) %&gt;% mutate_at(.vars = c(&quot;Quantity&quot;,&quot;Price&quot;), .funs = list(&quot;centered&quot; = center)) %&gt;% ungroup() # for better comparison in stargazer paneldata_demeaned &lt;- with(paneldata, data.frame(Quantity = Quantity - ave(Quantity, Location), Price = Price - ave(Price, Location))) # Pooling pooling &lt;- lm(Quantity ~ Price - 1, data=paneldata) # First Difference Estimation FD &lt;- lm(dQ ~ dP -1, data=paneldata) names(FD$coefficients) &lt;- c(&#39;Price&#39;) # Time demean TDM &lt;- lm(Quantity ~ Price -1, data=paneldata_demeaned) # Fixed Effects library(plm) FE &lt;- plm(Quantity ~ Price -1, data=paneldata, model=&quot;within&quot;, index = c(&quot;Location&quot;,&quot;Year&quot;)) # Least Squares Dummy Variable Estimation (Individual FE) LSDV &lt;- lm(Quantity ~ Price + Location -1, data=paneldata) # Stargazer Comparison library(stargazer) stargazer(pooling, FD, TDM, FE, LSDV, type=&quot;text&quot;, keep=c(&quot;Price&quot;), column.labels=c(&quot;Pooling&quot;, &quot;FD&quot;, &quot;TD&quot;, &quot;FE&quot;, &quot;LSDV&quot;), dep.var.labels.include = FALSE, model.numbers = FALSE, omit.stat=&quot;f&quot;) #&gt; #&gt; ========================================================================================= #&gt; Dependent variable: #&gt; --------------------------------------------------------------------- #&gt; OLS OLS OLS panel OLS #&gt; linear #&gt; Pooling FD TD FE LSDV #&gt; ----------------------------------------------------------------------------------------- #&gt; Price 0.021*** -0.021*** -0.021*** -0.021*** -0.021*** #&gt; (0.002) (0.003) (0.002) (0.003) (0.003) #&gt; #&gt; ----------------------------------------------------------------------------------------- #&gt; Observations 8 4 8 8 8 #&gt; R2 0.953 0.950 0.950 0.950 1.000 #&gt; Adjusted R2 0.947 0.933 0.943 0.883 1.000 #&gt; Residual Std. Error 0.314 (df = 7) 0.034 (df = 3) 0.016 (df = 7) 0.024 (df = 3) #&gt; ========================================================================================= #&gt; Note: *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01 "],["first-difference.html", "Chapter 13 First Difference 13.1 Application: Mincer earnings function 13.2 Data Management (4 pt) 13.3 Data Visualization (2 pt) 13.4 Data Modeling (2 pt) 13.5 Minimal Example", " Chapter 13 First Difference 13.1 Application: Mincer earnings function 13.2 Data Management (4 pt) # Load data library(haven) library(tidyverse) library(magrittr) # Read pl &lt;- readRDS(&quot;./SOEPteaching/pl_reduced.rds&quot;) pequiv &lt;- readRDS(&quot;./SOEPteaching/pequiv_reduced.rds&quot;) # Merge data master &lt;- merge(pl, pequiv, by = c(&quot;pid&quot;, &quot;syear&quot;)) All negative values represent missing values. Do a complete case analysis (n should be 338892). Drop all Stata labels with remove_all_labels() from sjlabelled package. # Drop missings master[master &lt; 0] &lt;- NA master &lt;- master[complete.cases(master), ] # Drop labels library(sjlabelled) master &lt;- remove_all_labels(master) Calculate each information in master per individual (group by id). Rename plh0182 to satis, d11109 to years_educ and d11101 to age. Hourly wages can be calculated as total annual income (ijob1) divided by total annual work hours (e11101). You may store log of hourly wage as a separate column/variable log_inc_hourly. Please filter for annual work hours larger than 0 (otherwise results might be Inf), before dividing. Please filter for hourly wages larger than 1, before taking the log. Years of schooling are readily available in SOEP. Tenure is not available in SOEP. Reilich (2011) suggests \"Experience is the potential experience following Mincer. We calculate the age minus the years of schooling minus 6 and minus the number of years with the experience of being unemployed.\". Calculate tenure like this tenure = age - years_educ - 6 - years_unemp. Calculate the number of years being unemployed years_unemp as the number of observations per individual minus the sum of all years that this individual was employed. e11102 is the employment status (0 for unemployed, 1 for employed) in a particular year. Some people exhibit negative tenure for various reasons. Filter for positive values. Store the prepared data as mincer. Summary statistics should roughly be equal to the following table: # Data stuff mincer &lt;- master %&gt;% rename(satis = plh0182, years_educ = d11109, age = d11101) %&gt;% group_by(pid) %&gt;% filter(e11101 &gt; 0) %&gt;% mutate(inc_hourly = ijob1/e11101) %&gt;% filter(inc_hourly &gt; 1) %&gt;% mutate(log_inc_hourly = log(inc_hourly)) %&gt;% mutate(years_obs = n()) %&gt;% mutate(years_emp = sum(e11102)) %&gt;% mutate(years_unemp = n() - sum(e11102)) %&gt;% mutate(tenure = age - years_educ - 6 - years_unemp) %&gt;% filter(tenure &gt; 0) %&gt;% arrange(pid) #select(c(&quot;pid&quot;, &quot;syear&quot;, &quot;years_educ&quot;, &quot;tenure&quot;, &quot;inc_hourly&quot;, &quot;log_inc_hourly&quot;)) mincer &lt;- as.data.frame(mincer) library(stargazer) stargazer(mincer[,c(3:5)], type=&quot;text&quot;) library(gtsummary) mincer %&gt;% select(&quot;years_educ&quot;, &quot;tenure&quot;, &quot;inc_hourly&quot;) %&gt;% tbl_summary() %&gt;% bold_labels() %&gt;% add_n() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #ogueufmkvt .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #ogueufmkvt .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #ogueufmkvt .gt_caption { padding-top: 4px; padding-bottom: 4px; } #ogueufmkvt .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #ogueufmkvt .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #ogueufmkvt .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #ogueufmkvt .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #ogueufmkvt .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #ogueufmkvt .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #ogueufmkvt .gt_column_spanner_outer:first-child { padding-left: 0; } #ogueufmkvt .gt_column_spanner_outer:last-child { padding-right: 0; } #ogueufmkvt .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #ogueufmkvt .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #ogueufmkvt .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #ogueufmkvt .gt_from_md > :first-child { margin-top: 0; } #ogueufmkvt .gt_from_md > :last-child { margin-bottom: 0; } #ogueufmkvt .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #ogueufmkvt .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #ogueufmkvt .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #ogueufmkvt .gt_row_group_first td { border-top-width: 2px; } #ogueufmkvt .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #ogueufmkvt .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #ogueufmkvt .gt_first_summary_row.thick { border-top-width: 2px; } #ogueufmkvt .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #ogueufmkvt .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #ogueufmkvt .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #ogueufmkvt .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #ogueufmkvt .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #ogueufmkvt .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #ogueufmkvt .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #ogueufmkvt .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #ogueufmkvt .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #ogueufmkvt .gt_left { text-align: left; } #ogueufmkvt .gt_center { text-align: center; } #ogueufmkvt .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #ogueufmkvt .gt_font_normal { font-weight: normal; } #ogueufmkvt .gt_font_bold { font-weight: bold; } #ogueufmkvt .gt_font_italic { font-style: italic; } #ogueufmkvt .gt_super { font-size: 65%; } #ogueufmkvt .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #ogueufmkvt .gt_asterisk { font-size: 100%; vertical-align: 0; } #ogueufmkvt .gt_indent_1 { text-indent: 5px; } #ogueufmkvt .gt_indent_2 { text-indent: 10px; } #ogueufmkvt .gt_indent_3 { text-indent: 15px; } #ogueufmkvt .gt_indent_4 { text-indent: 20px; } #ogueufmkvt .gt_indent_5 { text-indent: 25px; } Characteristic N N = 189,5141 pid 189,514 2,977,501 (505,402, 20,009,405) years_educ 189,514 11.50 (10.50, 13.50) tenure 189,514 24 (14, 32) inc_hourly 189,514 12 (8, 17) 1 Median (IQR) 13.3 Data Visualization (2 pt) The graph shows the hourly wage (not logged) in relation to the work experience for 5 random people that are observed for at least 5 years. You can use the sample_n_groups() function from previous exercises. sample_n_groups = function(grouped_df, size, replace = FALSE, weight=NULL) { grp_var &lt;- grouped_df %&gt;% groups %&gt;% unlist %&gt;% as.character random_grp &lt;- grouped_df %&gt;% summarise() %&gt;% sample_n(size, replace, weight) %&gt;% mutate(unique_id = 1:NROW(.)) grouped_df %&gt;% right_join(random_grp, by=grp_var) %&gt;% group_by_(grp_var) } library(ggplot2) set.seed(44) mincer %&gt;% group_by(pid) %&gt;% nest() %&gt;% filter(purrr::map_lgl(data, ~ nrow(.x) &gt;= 5)) %&gt;% unnest() %&gt;% sample_n_groups(5) %&gt;% # select 3 pid for all time ggplot(aes(x = tenure, y = inc_hourly, col=factor(pid))) + geom_line() + geom_point() + labs(title=&quot;Income and Work Experience&quot;, subtitle=&quot;Selected Sample of 5 People&quot;, x=&quot;Work Experience (Years)&quot;, y=&quot;Hourly Wage (Euro)&quot;, colour=&quot;person&quot;) + # give some illustrative labels theme(legend.position = &quot;none&quot;) 13.4 Data Modeling (2 pt) We select a subset of data for the years 2017 and 2018 (T=2). We calculate a pooling model, first difference and fixed effects. We use the plm package for all model setups. Estimate models without education and without the constant: \\[\\ln w_{it} = \\beta_1 \\text{tenure}_{it} + \\beta_2 \\text{tenure}^2_{it} \\] mincer1718 &lt;- mincer %&gt;% filter(syear == 2017 | syear == 2018) # OLS library(plm) LM2 &lt;- plm(log_inc_hourly ~ tenure + I(tenure^2) -1, data=mincer1718, model=&quot;pooling&quot;, index = c(&quot;pid&quot;,&quot;syear&quot;)) # Fixed Effects FE2 &lt;- plm(log_inc_hourly ~ tenure + I(tenure^2) -1, data=mincer1718, model=&quot;within&quot;, index = c(&quot;pid&quot;,&quot;syear&quot;)) # Fixed Effects FD2 &lt;- plm(log_inc_hourly ~ tenure + I(tenure^2) -1, data=mincer1718, model=&quot;fd&quot;, index = c(&quot;pid&quot;,&quot;syear&quot;)) Create a stargazer table for model comparison, such as: # Stargazer Comparison library(stargazer) stargazer(LM2, FD2, FE2, type=&quot;text&quot;, column.labels=c(&quot;Pooling&quot;, &quot;FD&quot;, &quot;FE&quot;), #keep=c(&quot;inc&quot;), dep.var.labels.include = FALSE, model.numbers = FALSE, omit.stat=&quot;f&quot;) #&gt; #&gt; ========================================== #&gt; Dependent variable: #&gt; ----------------------------- #&gt; Pooling FD FE #&gt; ------------------------------------------ #&gt; tenure 0.203*** 0.077*** 0.077*** #&gt; (0.001) (0.012) (0.012) #&gt; #&gt; I(tenure2) -0.003*** -0.001*** -0.001*** #&gt; (0.00002) (0.0002) (0.0002) #&gt; #&gt; ------------------------------------------ #&gt; Observations 15,440 6,229 15,440 #&gt; R2 0.106 0.0003 0.015 #&gt; Adjusted R2 0.106 0.0001 -1.443 #&gt; ========================================== #&gt; Note: *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01 13.5 Minimal Example Please create a minimal working example to illustrate the differences between FD and FE. How minimal can it be? MWE &lt;- data.frame(id = c(1,1,1,1,1,1,1,2,2,2,2,2,2,2), time = seq(from=1, to=7, by=1), married = c(0,0,1,1,0,1,1, 0,0,1,1,0,1,1), happy = c(5,5,8,7,4,7,5, 7,7,9,8,5,8,6)) #married = c(0,0,1,1,0,1,1, 1,1,0,0,0,1,0), #happy = c(6,5,8,7,4,7,5, 7,7,3,3,5,5,6)) #married = round(runif(14, min = 0, max = 1),0), #happy = round(runif(14, min = 4, max = 10),0)) Create a dataset MWE for two people (id 1 and 2) with 7 observations (time periods from 1 to 7). Create two variables. A dummy called married (regressor) and a happiness outcome variable (natural numbers ranging from 0 to 10). You may create the values of married and happy manually. Create a line plot for happiness over time colored by each individual. (In total, you should have two lines of different color.) Mark the marriage status by any reasonable label (there are several options in ggplot). library(ggplot2) ggplot(MWE, aes(x = time, y = happy, col=factor(id))) + geom_line(position = position_jitter(w = 0.2, h = 0.2)) + geom_point(aes(shape=factor(married)), size=4, position = position_jitter(w = 0.2, h = 0.2)) + labs(title=&quot;Marriage and Happiness&quot;, subtitle = &quot;Jitter added to confuse the reader.&quot;, x=&quot;Time (Years)&quot;, y=&quot;Happiness&quot;, colour=&quot;Person&quot;, shape=&quot;Marriage&quot;) Calculate a FE and FD estimator for how the marriage dummy affects happiness. Play around with different values and see how the FE and FD estimators changes. Select values such that FD is reasonable higher than FE. The two models look like this: # Fixed Effects FE_marry &lt;- plm(happy ~ married -1, data=MWE, model=&quot;within&quot;, index = c(&quot;id&quot;,&quot;time&quot;)) #FE_marry &lt;- lm(happy ~ married + as.factor(id), data=MWE) # First Difference FD_marry &lt;- plm(happy ~ married -1, data=MWE, model=&quot;fd&quot;, index = c(&quot;id&quot;,&quot;time&quot;)) stargazer(FE_marry, FD_marry, type=&quot;text&quot;, column.labels=c(&quot;FE&quot;, &quot;FD&quot;), keep=c(&quot;married&quot;), dep.var.labels.include = FALSE, model.numbers = FALSE) #&gt; #&gt; ===================================================== #&gt; Dependent variable: #&gt; ---------------------------- #&gt; FE FD #&gt; ----------------------------------------------------- #&gt; married 1.750** 2.833*** #&gt; (0.592) (0.405) #&gt; #&gt; ----------------------------------------------------- #&gt; Observations 14 12 #&gt; R2 0.443 0.883 #&gt; Adjusted R2 0.341 0.883 #&gt; F Statistic (df = 1; 11) 8.741** 48.908*** #&gt; ===================================================== #&gt; Note: *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01 From this table, it can be seen that the immediate impact getting married (2.83) is higher than the overall level difference of being married (1.75). "],["software-is-everywhere.html", "Chapter 14 Software is everywhere 14.1 Software 14.2 File formats", " Chapter 14 Software is everywhere \"The Zen of Organization is not to be found in Fancy Software.\" --- Kieran Healy. 2019. Data is inseparable from software.14 Data comes in various file formats that are connected to a specific software. Although most software can handle most of the common file formats. So, if almost all software can handle almost all data, how should we choose one? When choosing a software for data analysis there are many factors to consider:15 Does it run on your computer? Can you afford it? Do your colleagues use it? Does the software provide all the methods you need? Reading Kieran Healy (2019): The Plain Person’s Guide to Plain Text Social Science Kieran is speaking about two revolutions in computing. One puts single-purpose application in the foreground and by this hides the workings of the researcherdata scientistinternet backboneoperating system from the user. On the other side, open-source tools for licensingplain-text codingfundingkangaroos, data analysis, and writing are also better and more accessible than they have ever been. 14.1 Software Irrespective of the software, how to talk with it? 14.1.1 Command line interface (CLI) A command-line interpreter or command-line processor uses a command-line interface (CLI) to receive commands from a user in the form of lines of text. To open up the command prompt (on Windows), just press the windows key and search for cmd. When R is installed, it comes with a utility called Rscript. This allows you to run R commands from the command line. If Rscript is in your PATH, then typing Rscript into the command line, and pressing enter, will not result in an error. Otherwise, you might get a message saying “‘Rscript’ is not recognized as an internal or external command.” If that’s the case, then to use Rscript, you will either need to add it to your PATH (as an environment variable), or append the full directory of the location of Rscript on your machine. To find the full directory, search for where R is installed your computer. Figure 14.1: Command Line Interface on Windows with R The above example runs the commands 1*2*3*4 factorial(4) class(4) 1:4 14.1.2 Graphical user interface (GUI) The GUI, graphical user interface, is a form of user interface that allows users to interact with electronic devices through graphical icons and audio indicator such as primary notation, instead of text-based UIs, typed command labels or text navigation. GUIs were introduced in reaction to the perceived steep learning curve of CLIs (command-line interfaces), which require commands to be typed on a computer keyboard. Figure 14.2: RGui on Windows. Feels like no GUI. When you can click File -&gt; Open, you are on a GUI. 14.1.3 Integrated development environment (IDE) RStudio is an integrated development environment (IDE) for R. \"The RStudio IDE is a set of integrated tools designed to help you be more productive with R and Python. It includes a console, syntax-highlighting editor that supports direct code execution, and a variety of robust tools for plotting, viewing history, debugging and managing your workspace.\" RStudio RStudio comes with four panes Source Editor (open, edit and execute R code) Console (type and execute R code, it is like the command line) Environment (shows objects) Misc tabs (file manager, plots, package manager, help, ...) Figure 14.3: Graphical User Interface in RStudio 14.1.4 Online Compiler An online compiler allows to test a statistical (or programming) language, without any download, install or payment. There are various programming and web languages available at https://onecompiler.com/. The type setting processor LaTeX can be tested on https://www.overleaf.com/. Your Turn Copy paste the code in the console below. Click Run. Scroll for results. 1*2*3*4 factorial(4) class(4) 1:4 14.1.5 Cloud solutions You can pay for software as a service and use cloud computing for data analysis. Here are two cloud IDE: Posit Cloud: https://posit.cloud/ Codeanywhere: https://codeanywhere.com/ These cloud services are free with limited resources. You can buy more computational power or storage. Hardware, software and energy cost money. Amazing Fact Google’s own estimate which is a decade old shows that the energy required to power a Google search could power a low energy (10 watt) light bulb for 108 seconds. Read more on: fullfact.org 14.1.6 Dashboards A dashboard is a type of graphical user interface which often provides at-a-glance views of key performance indicators. It can be thought of as another form of a report and considered a form of data visualization. Dashboards have been common in business and finance. The COVID-19 pandemic of 2020 brought dashboards to the fore, with the Johns Hopkins and the RKI coronavirus tracker being good examples. Software to built dashboards is Microsoft Power BI, Tableau and of course R (flexdashboard and shinydashboard). 14.1.7 Shiny Apps R Shiny is an R package that makes it easy to build interactive web apps straight from R. You can host standalone apps on a webpage or embed them in R Markdown documents or build dashboards. You can also extend your Shiny apps with CSS themes, htmlwidgets, and JavaScript actions. Those apps allow the user some form of interaction with the data. 14.2 File formats 14.2.1 Text files A text file is a simple way of storing information line by line. Imagine the following dialogue. 11.04.20, 09:05 - Mum: Marcus discipulus est. 11.04.20, 10:46 - Marco: Tabellam tenet. 11.04.20, 10:53 - Mum: Scholam intrat, grammaticum salutat. 11.04.20, 10:46 - Marco: Graece et Latine scribere et legere libenter discit. 11.04.20, 10:46 - Mum: Grammaticum autem timet. It represents the typical structure of a WhatsApp chat export, i.e. DATE, TIME - AUTHOR: MESSAGE The information is separated by comma, hyphen and colon. A .txt file can be opened with any text editor. Other notable file types can be opened and read by a human with a text editor as well, e.g. an R script (ending .R) or R Markdown file (ending .Rmd). Here is the minimal file chat.txt. #&gt; [1] &quot;11.04.20, 09:05 - Mum: Marcus discipulus est. &quot; #&gt; [2] &quot;11.04.20, 10:46 - Marco: Tabellam tenet. &quot; #&gt; [3] &quot;11.04.20, 10:53 - Mum: Scholam intrat, grammaticum salutat. &quot; #&gt; [4] &quot;11.04.20, 10:46 - Marco: Graece et Latine scribere et legere libenter discit.&quot; #&gt; [5] &quot;11.04.20, 10:46 - Mum: Grammaticum autem timet.&quot; 14.2.2 Text with structure The trusty .csv (comma separated values) file is, still, one of the most common file types for data storage and exchange. It is knocking around ten years before the first personal computer. A .csv file stores tabular data in plain text format. Each line is a data record and each record has one or more fields, separated by commas. Tabular data can also be separated by a TAB or semicolon. Definition Tabular data refers to data that is organized in a table with rows and columns. Within the table, the rows represent observations and the columns represent attributes. Here is the minimal file chat.csv. #&gt; Date Time Name Message #&gt; 1 11.04.20 09:05 Mum Marcus discipulus est. #&gt; 2 11.04.20 10:46 Marco Tabellam tenet. #&gt; 3 11.04.20 10:53 Mum Scholam intrat, grammaticum salutat. #&gt; 4 11.04.20 10:46 Marco Graece et Latine scribere et legere libenter discit. #&gt; 5 11.04.20 10:46 Mum Grammaticum autem timet. Truly Dedicated Do you think text information is outdated? If you have a Netflix account, request your data from Netflix. It's easy and fun. Check what Netflix knows about your devices, ratings, profiles, avatars, subscriptions, billing and more. It comes in about two dozen .txt and .csv files. 14.2.3 File formats Interesting file types The .xlsx file is Microsoft Excel Open XML Format Spreadsheet file. The .dta file is a proprietary binary format designed for use as the native format for datasets with Stata, a system for statistics and data analysis. Stata 1.0 was released in 1985 for the IBM PC. The .sav file is from SPSS. The .Rdata file comes from R. The .JSON stand for JavaScript Object Notation. JSON is a standard text-based format for representing structured data based on JavaScript object syntax. Reading Amazing information on file formats (file-format classes, bitstream structures etc.) can be found at Library of Congress Collections. How to choose between file formats? Think about it. CSV’s are costing you time, disk space, and money. It’s time to end it. Picture this — you collect large volumes of data and store them in the cloud. You didn’t do much research on file formats, so you opt for CSVs. Your expenses are through the roof! A simple tweak can reduce them by half, if not more. That tweak is — you’ve guessed it — choosing a different file format. Dario Radečić (2021) Stop Using CSVs for Storage — This File Format Is 150 Times Faster .feather is a young file format created to improve exchange of data between R and Python. Feather is a fast, lightweight, and easy-to-use binary file format for storing data frames. Check the category of data analysis software and the list of statistical software.↩︎ Check out the versatile discussion on the measurement of data analysis software popularity by Robert München: The Popularity of Data Analysis Software↩︎ "],["references.html", "References 14.3 Resources", " References 14.3 Resources https://informationisbeautiful.net/ "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
